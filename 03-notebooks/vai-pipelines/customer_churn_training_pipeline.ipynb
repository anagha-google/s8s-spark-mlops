{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a212fa6e-2198-41c6-9e69-8d7abb407684",
   "metadata": {},
   "source": [
    "# MLOps with Spark MLLib & Vertex AI Pipelines\n",
    "In the prior lab modules - <br>(1) We authored Spark code in Serverless Spark interactive notebooks in Vertex AI workbench. <br>(2) We then created PySpark scripts off of them and tested them manually on cloud shell. <br> In this notebook -<br> (3) We will create a Vertex AI pipeline for MLOps - essentially chaining together the serverless Spark applications we developed in (2)<br> In a subsequent modules -<br>(4) We will create a Google Cloud Function to execute the pipeline and <br> (5) Finally, we will call that Google Cloud Function via Cloud Scheduler to complete the automation.\n",
    "We will compile the pipeline JSON and use the same to schedule with Cloud Scheduler separately.\n",
    "\n",
    "Dependency: Custom container image for Serverless Spark (already) created as part of (your) Terraform-based environment provisioning if you have created your environment using the Terraform provided in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb5a414-f457-4e23-8c8e-62200dc6cfe7",
   "metadata": {},
   "source": [
    "### 1. One time setup of dependencies\n",
    "Uncomment the cell below, and run just the cell, one time ONLY to install necessary libraries - AND THEN comment it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "548c98b0-89c9-4eca-bd1d-a39ac780c747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip3 install --user --upgrade google-cloud-aiplatform==1.11.0 kfp==1.8.11 google-cloud-pipeline-components==1.0.1 --quiet --no-warn-conflicts\\n\\n# Automatically restart kernel after installs\\nimport os\\nif not os.getenv(\"IS_TESTING\"):\\n    # Automatically restart kernel after installs\\n    import IPython\\n\\n    app = IPython.Application.instance()\\n    app.kernel.do_shutdown(True)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip3 install --user --upgrade google-cloud-aiplatform==1.11.0 kfp==1.8.11 google-cloud-pipeline-components==1.0.1 --quiet --no-warn-conflicts\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46e6a9-0c11-42fe-9595-3007cfcfb0ef",
   "metadata": {},
   "source": [
    "### 2. Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d34ff675-62e7-410f-b619-f1f8d8ab0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path as path\n",
    "from typing import NamedTuple\n",
    "import os\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google_cloud_pipeline_components import aiplatform as vertex_ai_components\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import (Artifact, ClassificationMetrics, Condition, Input,\n",
    "                        Metrics, Output, component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a129398-d241-47b8-8063-73b605a936d8",
   "metadata": {},
   "source": [
    "#### a. Project specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ed589bb-8ed3-4cb0-96c4-462a310d1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  gcp-scalable-ml-workshop\n",
      "Project Number:  569379262211\n",
      "UMSA FQN:  s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\n",
      "UNIQUE ID:  2593\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "PROJECT_NBR = \"\"\n",
    "UNIQUE_ID = random.randint(1, 10000)\n",
    "WITHOUT_TASK_CACHING = True\n",
    "BYO_NETWORK = True\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = project_id_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "    \n",
    "    \n",
    "    project_nbr_output = !gcloud projects describe $PROJECT_ID --format='value(projectNumber)'\n",
    "    PROJECT_NBR = project_nbr_output[0]\n",
    "    print(\"Project Number: \", PROJECT_NBR)\n",
    "    \n",
    "umsa_output = !gcloud config list account --format \"value(core.account)\"\n",
    "UMSA_FQN = umsa_output[0]\n",
    "print(\"UMSA FQN: \", UMSA_FQN)\n",
    "print(\"UNIQUE ID: \", UNIQUE_ID)\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f040cba-24ce-4550-93a7-b851d732f301",
   "metadata": {},
   "source": [
    "#### b. Local resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a231439c-6ae0-4847-8c3f-8ee23c4c5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_BASE_NM = \"customer-churn-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96e1340b-3af1-4f95-a763-b8a1e7ca1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_SCRATCH_DIR = path(f\"/home/jupyter/scratch/{APP_BASE_NM}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "760f8ece-197a-4c9e-be28-03619594bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -m 777 -p $LOCAL_SCRATCH_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca50a5dc-d66c-4ff7-a408-db038568ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 144\n",
      "drwxrwxrwx 3 jupyter jupyter  4096 Sep 30 18:47 .\n",
      "drwxr-xr-x 3 jupyter jupyter  4096 Aug 29 21:16 ..\n",
      "drwxr-xr-x 2 jupyter jupyter  4096 Sep 28 19:38 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 jupyter jupyter 41020 Aug 30 15:34 pipeline_2828.json\n",
      "-rw-r--r-- 1 jupyter jupyter 41594 Sep 30 20:30 pipeline_321.json\n",
      "-rw-r--r-- 1 jupyter jupyter 41020 Sep 28 19:32 pipeline_4381.json\n"
     ]
    }
   ],
   "source": [
    "!ls -al $LOCAL_SCRATCH_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af5a57b5-4cfc-48cb-9f88-cd437353b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/scratch/customer-churn-model\n"
     ]
    }
   ],
   "source": [
    "!cd $LOCAL_SCRATCH_DIR && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "593ff06b-8ac6-499d-a988-50b93d0e58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 252\n",
      "drwxr-xr-x 12 jupyter jupyter   4096 Sep 30 20:33 .\n",
      "drwxr-xr-x  3 root    root      4096 Aug 25 16:05 ..\n",
      "drwxr-xr-x  5 jupyter jupyter   4096 Aug 29 21:15 .cache\n",
      "drwxr-xr-x  4 jupyter jupyter   4096 Aug 25 16:05 .config\n",
      "drwxr-xr-x  2 jupyter jupyter   4096 Aug 25 16:05 .docker\n",
      "drwxr-xr-x  2 jupyter jupyter   4096 Sep 30 18:47 .ipynb_checkpoints\n",
      "drwxr-xr-x  5 jupyter jupyter   4096 Aug 25 18:13 .ipython\n",
      "drwxr-xr-x  3 jupyter jupyter   4096 Aug 25 17:37 .jupyter\n",
      "drwxr-xr-x  5 jupyter jupyter   4096 Aug 29 21:15 .local\n",
      "-rw-r--r--  1 jupyter jupyter 206468 Sep 30 20:33 customer_churn_training_pipeline-Copy1.ipynb\n",
      "drwxr-xr-x  3 jupyter jupyter   4096 Aug 29 21:16 scratch\n",
      "drwxr-xr-x  3 jupyter jupyter   4096 Aug 25 16:05 src\n",
      "drwxr-xr-x  4 jupyter jupyter   4096 Aug 25 16:05 tutorials\n"
     ]
    }
   ],
   "source": [
    "!ls -al /home/jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7b7a0-4281-4d6b-9cec-7fed2b300b44",
   "metadata": {},
   "source": [
    "#### d. The pre-created resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "347c9514-0d95-47f7-9671-1c2b5ff73255",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_BUCKET = f\"gs://s8s_code_bucket-{PROJECT_NBR}\"\n",
    "DATA_BUCKET = f\"gs://s8s_data_bucket-{PROJECT_NBR}\"\n",
    "MODEL_BUCKET = f\"gs://s8s_model_bucket-{PROJECT_NBR}\"\n",
    "SCRATCH_BUCKET = f\"s8s-spark-bucket-{PROJECT_NBR}\"\n",
    "BQ_DS_NM = f\"{PROJECT_ID}.customer_churn_ds\"\n",
    "LOCATION = \"us-central1\"\n",
    "VPC_NM = f\"s8s-vpc-{PROJECT_NBR}\"\n",
    "SUBNET_RESOURCE_URI = f\"projects/{PROJECT_ID}/regions/{LOCATION}/subnetworks/spark-snet\"\n",
    "PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI = f\"projects/{PROJECT_ID}/regions/{LOCATION}/clusters/s8s-sphs-{PROJECT_NBR}\"\n",
    "GCR_REPO_NM = f\"s8s-spark-{PROJECT_NBR}\"\n",
    "DOCKER_IMAGE_TAG = \"1.0.0\"\n",
    "DOCKER_IMAGE_NM = \"customer_churn_image\"\n",
    "DOCKER_IMAGE_FQN = f\"gcr.io/{PROJECT_ID}/{DOCKER_IMAGE_NM}:{DOCKER_IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab3891-5f9d-40f3-b709-80754abe8d1d",
   "metadata": {},
   "source": [
    "#### e. Pipeline entity specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6858b5a-40bd-4705-9a77-2dc3fd97eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ID = 2593\n",
      "PIPELINE_NM = customer-churn-model-pipeline\n",
      "PIPELINE_PACKAGE_SRC_LOCAL_PATH = /home/jupyter/scratch/customer-churn-model/pipeline_2593.json\n",
      "PIPELINE_ROOT_GCS_URI = gs://s8s_model_bucket-569379262211/customer-churn-model/pipelines\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_ID = UNIQUE_ID\n",
    "PIPELINE_NM = f\"{APP_BASE_NM}-pipeline\"\n",
    "PIPELINE_PACKAGE_SRC_LOCAL_PATH = f\"{LOCAL_SCRATCH_DIR}/pipeline_{PIPELINE_ID}.json\"\n",
    "PIPELINE_ROOT_GCS_URI = f\"{MODEL_BUCKET}/{APP_BASE_NM}/pipelines\"\n",
    "\n",
    "print('PIPELINE_ID =',PIPELINE_ID)\n",
    "print('PIPELINE_NM =',PIPELINE_NM)\n",
    "print('PIPELINE_PACKAGE_SRC_LOCAL_PATH =',PIPELINE_PACKAGE_SRC_LOCAL_PATH)\n",
    "print('PIPELINE_ROOT_GCS_URI =',PIPELINE_ROOT_GCS_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a93fba-9714-46dc-b8f7-929331c159dc",
   "metadata": {},
   "source": [
    "#### d. Pipeline stage agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c437c615-18eb-4aa1-92ef-65a6af02a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY_SCRIPTS_FQP = gs://s8s_code_bucket-569379262211/pyspark\n",
      "PYSPARK_COMMON_UTILS_SCRIPT_FQP = ['gs://s8s_code_bucket-569379262211/pyspark/common_utils.py']\n"
     ]
    }
   ],
   "source": [
    "PY_SCRIPTS_FQP = f\"{CODE_BUCKET}/pyspark\"\n",
    "PYSPARK_COMMON_UTILS_SCRIPT_FQP = [f\"{PY_SCRIPTS_FQP}/common_utils.py\"]\n",
    "\n",
    "print('PY_SCRIPTS_FQP =',PY_SCRIPTS_FQP)\n",
    "print('PYSPARK_COMMON_UTILS_SCRIPT_FQP =',PYSPARK_COMMON_UTILS_SCRIPT_FQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf673b2e-89c6-4eaf-bb8b-69b206f84814",
   "metadata": {},
   "source": [
    "#### e. Data preprocessing stage specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d881fbc3-ee62-4969-928d-55a44dd2219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PREPROCESSING_BATCH_INSTANCE_ID = customer-churn-model-preprocessing-2593\n",
      "DATA_PREPROCESSING_MAIN_PY_SCRIPT = gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\n",
      "DATA_PROCESSING_SINK = gcp-scalable-ml-workshop.customer_churn_ds.training_data\n",
      "DATA_PROCESSING_BQ_SINK_URI = bq://gcp-scalable-ml-workshop.customer_churn_ds.training_data\n",
      "DATA_PREPROCESSING_ARGS = ['--pipelineID=2593', '--projectID=gcp-scalable-ml-workshop', '--projectNbr=569379262211', '--displayPrintStatements=True']\n"
     ]
    }
   ],
   "source": [
    "DATA_PREPROCESSING_BATCH_PREFIX = \"preprocessing\"\n",
    "DATA_PREPROCESSING_BATCH_INSTANCE_ID = f\"{APP_BASE_NM}-{DATA_PREPROCESSING_BATCH_PREFIX}-{UNIQUE_ID}\"\n",
    "DATA_PREPROCESSING_MAIN_PY_SCRIPT = f\"{PY_SCRIPTS_FQP}/preprocessing.py\"\n",
    "\n",
    "DATA_PROCESSING_SINK = f\"{BQ_DS_NM}.training_data\"\n",
    "DATA_PROCESSING_BQ_SINK_URI = f\"bq://{DATA_PROCESSING_SINK}\"\n",
    "\n",
    "DATA_PREPROCESSING_ARGS = [f\"--pipelineID={UNIQUE_ID}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--projectNbr={PROJECT_NBR}\", \n",
    "        f\"--displayPrintStatements={True}\"]\n",
    "\n",
    "print('DATA_PREPROCESSING_BATCH_INSTANCE_ID =',DATA_PREPROCESSING_BATCH_INSTANCE_ID)\n",
    "print('DATA_PREPROCESSING_MAIN_PY_SCRIPT =',DATA_PREPROCESSING_MAIN_PY_SCRIPT)\n",
    "print('DATA_PROCESSING_SINK =',DATA_PROCESSING_SINK)\n",
    "print('DATA_PROCESSING_BQ_SINK_URI =',DATA_PROCESSING_BQ_SINK_URI)\n",
    "print('DATA_PREPROCESSING_ARGS =',DATA_PREPROCESSING_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca656c-5ae8-45ab-95a3-873fede76c01",
   "metadata": {},
   "source": [
    "#### f. Dataset registration specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50eae873-c8e8-4f0b-9bac-e83c58f64ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANAGED_DATASET_NM = f\"{APP_BASE_NM}-{UNIQUE_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d69e4b-d088-4293-a88e-5b4d943615c8",
   "metadata": {},
   "source": [
    "#### g. Model specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecfd7e0e-3b57-4c4d-a148-4357bf816b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_TRAINING_BATCH_INSTANCE_ID = customer-churn-model-training-2593\n",
      "MODEL_TRAINING_MAIN_PY_SCRIPT = gs://s8s_code_bucket-569379262211/pyspark/model_training.py\n",
      "MODEL_TRAINING_ARGS = ['--pipelineID=2593', '--projectID=gcp-scalable-ml-workshop', '--projectNbr=569379262211', '--displayPrintStatements=True']\n",
      "MODEL_METRICS_BUCKET_FQP = gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/2593/full/metrics.json\n"
     ]
    }
   ],
   "source": [
    "MODEL_TRAINING_BATCH_PREFIX = \"training\"\n",
    "MODEL_TRAINING_BATCH_INSTANCE_ID = f\"{APP_BASE_NM}-{MODEL_TRAINING_BATCH_PREFIX}-{UNIQUE_ID}\"\n",
    "MODEL_TRAINING_MAIN_PY_SCRIPT = f\"{PY_SCRIPTS_FQP}/model_training.py\"\n",
    "MODEL_TRAINING_ARGS = [f\"--pipelineID={UNIQUE_ID}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--projectNbr={PROJECT_NBR}\", \n",
    "        f\"--displayPrintStatements={True}\"]\n",
    "\n",
    "MODEL_METRICS_BUCKET_FQP = f\"gs://s8s_metrics_bucket-{PROJECT_NBR}/{APP_BASE_NM}/{MODEL_TRAINING_BATCH_PREFIX}/{UNIQUE_ID}/full/metrics.json\"\n",
    "\n",
    "print('MODEL_TRAINING_BATCH_INSTANCE_ID =',MODEL_TRAINING_BATCH_INSTANCE_ID)\n",
    "print('MODEL_TRAINING_MAIN_PY_SCRIPT =',MODEL_TRAINING_MAIN_PY_SCRIPT)\n",
    "print('MODEL_TRAINING_ARGS =',MODEL_TRAINING_ARGS)\n",
    "print('MODEL_METRICS_BUCKET_FQP =',MODEL_METRICS_BUCKET_FQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8f31c-44e3-44cc-8eb1-9eadf50c0137",
   "metadata": {},
   "source": [
    "#### h. Hyperparameter tuning specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5bfbc78c-8d1d-4590-a86d-925b35c3fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID = customer-churn-model-hyperparameter-tuning-2593\n",
      "HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT = gs://s8s_code_bucket-569379262211/pyspark/hyperparameter_tuning.py\n",
      "HYPERPARAMETER_TUNING_ARGS = ['--pipelineID=2593', '--projectID=gcp-scalable-ml-workshop', '--projectNbr=569379262211', '--displayPrintStatements=True']\n",
      "HYPERPARAMETER_TUNING_RUNTIME_CONFIGS = {'spark.jars.packages': 'ml.combust.mleap:mleap-spark-base_2.12:0.20.0,ml.combust.mleap:mleap-spark_2.12:0.20.0'}\n"
     ]
    }
   ],
   "source": [
    "# Condition\n",
    "AUPR_THRESHOLD = 0.5\n",
    "AUPR_HYPERTUNE_CONDITION = \"[AUPR_HYPERTUNE]\"\n",
    "\n",
    "HYPERPARAMETER_TUNING_BATCH_PREFIX = \"hyperparameter-tuning\"\n",
    "HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID = f\"{APP_BASE_NM}-{HYPERPARAMETER_TUNING_BATCH_PREFIX}-{UNIQUE_ID}\"\n",
    "HYPERPARAMETER_TUNING_ARGS = [f\"--pipelineID={UNIQUE_ID}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--projectNbr={PROJECT_NBR}\", \n",
    "        f\"--displayPrintStatements={True}\"]\n",
    "\n",
    "HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT = f\"{PY_SCRIPTS_FQP}/hyperparameter_tuning.py\"\n",
    "HYPERPARAMETER_TUNING_BUCKET_FQP = f\"gs://s8s_metrics_bucket-{PROJECT_NBR}/{APP_BASE_NM}/{HYPERPARAMETER_TUNING_BATCH_PREFIX}/{UNIQUE_ID}/full/metrics.json\"\n",
    "HYPERPARAMETER_TUNING_RUNTIME_CONFIGS = {\n",
    "    \"spark.jars.packages\": \"ml.combust.mleap:mleap-spark-base_2.12:0.20.0,ml.combust.mleap:mleap-spark_2.12:0.20.0\"\n",
    "}\n",
    "\n",
    "\n",
    "print('HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID =',HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID)\n",
    "print('HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT =',HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT)\n",
    "print('HYPERPARAMETER_TUNING_ARGS =',HYPERPARAMETER_TUNING_ARGS)\n",
    "print('HYPERPARAMETER_TUNING_RUNTIME_CONFIGS =',HYPERPARAMETER_TUNING_RUNTIME_CONFIGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e5090-1f28-4022-b3b1-82099710238b",
   "metadata": {},
   "source": [
    "### 3. Initialize Vertex AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9c54e20-c08a-40cf-8716-09de594df623",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=SCRATCH_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa4fd3-4b64-4946-a4ac-5937ad96a671",
   "metadata": {},
   "source": [
    "### 4. Define custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af80172f-b441-4104-98a0-3bf42dff4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.8\",\n",
    "    packages_to_install=[\"numpy==1.21.2\", \"pandas==1.3.3\", \"scikit-learn==0.24.2\"],\n",
    ")\n",
    "def fnEvaluateModel(\n",
    "    metricsUri: str,\n",
    "    metrics: Output[Metrics],\n",
    "    plots: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"threshold_metric\", float)]):\n",
    "\n",
    "    import json\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "    # Variables\n",
    "    metricsGCSMountPath = metricsUri.replace(\"gs://\", \"/gcs/\")\n",
    "    labels = [\"yes\", \"no\"]\n",
    "\n",
    "    # Helpers\n",
    "    def fnCalculateROC(metrics, true, score):\n",
    "        y_true_np = np.array(metrics[true])\n",
    "        y_score_np = np.array(metrics[score])\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y_true=y_true_np, y_score=y_score_np, pos_label=True\n",
    "        )\n",
    "        return fpr, tpr, thresholds\n",
    "\n",
    "    def fnCalculateConfusionMatrix(metrics, true, prediction):\n",
    "        y_true_np = np.array(metrics[true])\n",
    "        y_pred_np = np.array(metrics[prediction])\n",
    "        c_matrix = confusion_matrix(y_true_np, y_pred_np)\n",
    "        return c_matrix\n",
    "\n",
    "    # Main\n",
    "    with open(metricsGCSMountPath, mode=\"r\") as json_file:\n",
    "        metricsDictionary = json.load(json_file)\n",
    "\n",
    "    area_roc = metricsDictionary[\"test_area_roc\"]\n",
    "    area_prc = metricsDictionary[\"test_area_prc\"]\n",
    "    acc = metricsDictionary[\"test_accuracy\"]\n",
    "    f1 = metricsDictionary[\"test_f1\"]\n",
    "    prec = metricsDictionary[\"test_precision\"]\n",
    "    rec = metricsDictionary[\"test_recall\"]\n",
    "\n",
    "    metrics.log_metric(\"Test_areaUnderROC\", area_roc)\n",
    "    metrics.log_metric(\"Test_areaUnderPRC\", area_prc)\n",
    "    metrics.log_metric(\"Test_Accuracy\", acc)\n",
    "    metrics.log_metric(\"Test_f1-score\", f1)\n",
    "    metrics.log_metric(\"Test_Precision\", prec)\n",
    "    metrics.log_metric(\"Test_Recall\", rec)\n",
    "\n",
    "    fpr, tpr, thresholds = fnCalculateROC(metricsDictionary, \"true\", \"score\")\n",
    "    c_matrix = fnCalculateConfusionMatrix(metricsDictionary, \"true\", \"prediction\")\n",
    "    plots.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
    "    plots.log_confusion_matrix(labels, c_matrix.tolist())\n",
    "\n",
    "    componentOutputsTuple = NamedTuple(\n",
    "        \"Outputs\",\n",
    "        [\n",
    "            (\"threshold_metric\", float),\n",
    "        ],\n",
    "    )\n",
    "    return componentOutputsTuple(area_prc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3c111-17dc-4248-9df8-7c65f73c696c",
   "metadata": {},
   "source": [
    "### 5. Define Vertex AI Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902ec5e-54ec-4010-8f20-52e8c2ab6a6e",
   "metadata": {},
   "source": [
    "##### Option 1: In this version we dont disable task level caching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "346cdd5b-53a4-4760-b4f7-e595f7c20d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NM, \n",
    "    description=\"A SparkMLlib MLOps Vertex pipeline\")\n",
    "def fnSparkMlopsPipeline(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    location: str = LOCATION,\n",
    "    service_account: str = UMSA_FQN,\n",
    "    subnetwork_uri: str = SUBNET_RESOURCE_URI,\n",
    "    spark_phs_nm: str = PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI,\n",
    "    container_image: str = DOCKER_IMAGE_FQN,\n",
    "    common_utils_py_fqn: list = PYSPARK_COMMON_UTILS_SCRIPT_FQP,\n",
    "    data_preprocessing_pyspark_batch_id: str = DATA_PREPROCESSING_BATCH_INSTANCE_ID,\n",
    "    data_preprocessing_main_py_fqn: str = DATA_PREPROCESSING_MAIN_PY_SCRIPT,\n",
    "    data_preprocessing_args: list = DATA_PREPROCESSING_ARGS,\n",
    "    managed_dataset_display_nm: str = MANAGED_DATASET_NM,\n",
    "    managed_dataset_src_uri: str = DATA_PROCESSING_BQ_SINK_URI,\n",
    "    model_training_pyspark_batch_id: str = MODEL_TRAINING_BATCH_INSTANCE_ID,\n",
    "    model_training_main_py_fqn: str = MODEL_TRAINING_MAIN_PY_SCRIPT,\n",
    "    model_training_metrics_fqp: str = MODEL_METRICS_BUCKET_FQP,\n",
    "    model_training_args: list = MODEL_TRAINING_ARGS,\n",
    "    threshold: float = AUPR_THRESHOLD,\n",
    "    hyperparameter_tuning_pyspark_batch_id: str = HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID,\n",
    "    hyperparameter_tuning_main_py_fqn: str = HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT,\n",
    "    hyperparameter_tuning_args: list = HYPERPARAMETER_TUNING_ARGS,\n",
    "    hyperparameter_tuning_metrics_fqp: str = MODEL_METRICS_BUCKET_FQP,\n",
    "    hyperparameter_tuning_runtime_config_properties: dict = HYPERPARAMETER_TUNING_RUNTIME_CONFIGS\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.dataproc import \\\n",
    "        DataprocPySparkBatchOp\n",
    "\n",
    "    # Step 1. PRE-PROCESS DATA in PREP FOR MODEL TRAINING\n",
    "    # ....................................................................\n",
    "    preprocessingStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = data_preprocessing_pyspark_batch_id,\n",
    "        main_python_file_uri = data_preprocessing_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = data_preprocessing_args\n",
    "    ).set_display_name(\"Preprocessing\")\n",
    "    \n",
    "    \n",
    "    # Step 2. REGISTER PRE-PROCESSED DATA AS MANAGED DATASET\n",
    "    # ....................................................................\n",
    "    createManagedDatasetStep = vertex_ai_components.TabularDatasetCreateOp(\n",
    "        display_name= managed_dataset_display_nm,\n",
    "        bq_source=managed_dataset_src_uri,\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    ).after(preprocessingStep).set_display_name(\"Dataset registration\")\n",
    "    \n",
    "    # Step 3. TRAIN MODEL\n",
    "    # .................................................................... \n",
    "    trainSparkMLModelStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = model_training_pyspark_batch_id,\n",
    "        main_python_file_uri = model_training_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = model_training_args\n",
    "    ).after(preprocessingStep).set_display_name(\"Model training\")\n",
    "    \n",
    "    # Step 4. EVALUATE MODEL\n",
    "    # .................................................................... \n",
    "    evaluateModelStep = fnEvaluateModel(model_training_metrics_fqp).after(trainSparkMLModelStep).set_display_name(\"Evaluate model\")\n",
    "    \n",
    "    # Step 5. CONDITIONAL HYPERPARAMETER TUNING\n",
    "    # .................................................................... \n",
    "    with Condition(\n",
    "        evaluateModelStep.outputs[\"threshold_metric\"] >= threshold,\n",
    "        name=\"AUPR Threshold Exceeded\",\n",
    "    ):\n",
    "        # HYPERPARAMETER TUNING\n",
    "        hyperparameterTuningStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = hyperparameter_tuning_pyspark_batch_id,\n",
    "        main_python_file_uri = hyperparameter_tuning_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = hyperparameter_tuning_args,\n",
    "        runtime_config_properties = hyperparameter_tuning_runtime_config_properties\n",
    "        ).after(evaluateModelStep).set_display_name(\"Hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e6167-2446-4595-88ff-8d01880972ad",
   "metadata": {},
   "source": [
    "##### Option 2: In this version we disable task level caching\n",
    "Prefer this for scheduled execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb932bdd-8e1d-4a04-84bd-10bb6d7bd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NM, \n",
    "    description=\"A SparkMLlib MLOps Vertex pipeline\")\n",
    "def fnSparkMlopsPipelineWithoutCaching(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    location: str = LOCATION,\n",
    "    service_account: str = UMSA_FQN,\n",
    "    subnetwork_uri: str = SUBNET_RESOURCE_URI,\n",
    "    spark_phs_nm: str = PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI,\n",
    "    container_image: str = DOCKER_IMAGE_FQN,\n",
    "    common_utils_py_fqn: list = PYSPARK_COMMON_UTILS_SCRIPT_FQP,\n",
    "    data_preprocessing_pyspark_batch_id: str = DATA_PREPROCESSING_BATCH_INSTANCE_ID,\n",
    "    data_preprocessing_main_py_fqn: str = DATA_PREPROCESSING_MAIN_PY_SCRIPT,\n",
    "    data_preprocessing_args: list = DATA_PREPROCESSING_ARGS,\n",
    "    managed_dataset_display_nm: str = MANAGED_DATASET_NM,\n",
    "    managed_dataset_src_uri: str = DATA_PROCESSING_BQ_SINK_URI,\n",
    "    model_training_pyspark_batch_id: str = MODEL_TRAINING_BATCH_INSTANCE_ID,\n",
    "    model_training_main_py_fqn: str = MODEL_TRAINING_MAIN_PY_SCRIPT,\n",
    "    model_training_metrics_fqp: str = MODEL_METRICS_BUCKET_FQP,\n",
    "    model_training_args: list = MODEL_TRAINING_ARGS,\n",
    "    threshold: float = AUPR_THRESHOLD,\n",
    "    hyperparameter_tuning_pyspark_batch_id: str = HYPERPARAMETER_TUNING_BATCH_INSTANCE_ID,\n",
    "    hyperparameter_tuning_main_py_fqn: str = HYPERPARAMETER_TUNING_MAIN_PY_SCRIPT,\n",
    "    hyperparameter_tuning_args: list = HYPERPARAMETER_TUNING_ARGS,\n",
    "    hyperparameter_tuning_metrics_fqp: str = MODEL_METRICS_BUCKET_FQP,\n",
    "    hyperparameter_tuning_runtime_config_properties: dict = HYPERPARAMETER_TUNING_RUNTIME_CONFIGS\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.dataproc import \\\n",
    "        DataprocPySparkBatchOp\n",
    "\n",
    "    # Step 1. PRE-PROCESS DATA in PREP FOR MODEL TRAINING\n",
    "    # ....................................................................\n",
    "    preprocessingStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = data_preprocessing_pyspark_batch_id,\n",
    "        main_python_file_uri = data_preprocessing_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = data_preprocessing_args\n",
    "    ).set_caching_options(False).set_display_name(\"Preprocessing\")\n",
    "    \n",
    "    \n",
    "    # Step 2. REGISTER PRE-PROCESSED DATA AS MANAGED DATASET\n",
    "    # ....................................................................\n",
    "    createManagedDatasetStep = vertex_ai_components.TabularDatasetCreateOp(\n",
    "        display_name= managed_dataset_display_nm,\n",
    "        bq_source=managed_dataset_src_uri,\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    ).after(preprocessingStep).set_caching_options(False).set_display_name(\"Dataset registration\")\n",
    "    \n",
    "    # Step 3. TRAIN MODEL\n",
    "    # .................................................................... \n",
    "    trainSparkMLModelStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = model_training_pyspark_batch_id,\n",
    "        main_python_file_uri = model_training_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = model_training_args\n",
    "    ).set_caching_options(False).after(preprocessingStep).set_display_name(\"Model training\")\n",
    "    \n",
    "    # Step 4. EVALUATE MODEL\n",
    "    # .................................................................... \n",
    "    evaluateModelStep = fnEvaluateModel(model_training_metrics_fqp).after(trainSparkMLModelStep).set_caching_options(False).set_display_name(\"Evaluate model\")\n",
    "    \n",
    "    # Step 5. CONDITIONAL HYPERPARAMETER TUNING\n",
    "    # .................................................................... \n",
    "    with Condition(\n",
    "        evaluateModelStep.outputs[\"threshold_metric\"] >= threshold,\n",
    "        name=\"AUPR Threshold Exceeded\",\n",
    "    ):\n",
    "        # HYPERPARAMETER TUNING\n",
    "        hyperparameterTuningStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = hyperparameter_tuning_pyspark_batch_id,\n",
    "        main_python_file_uri = hyperparameter_tuning_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = hyperparameter_tuning_args,\n",
    "        runtime_config_properties = hyperparameter_tuning_runtime_config_properties\n",
    "        ).after(evaluateModelStep).set_caching_options(False).set_display_name(\"Hyperparameter tuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126d252-8cad-4615-bb65-1126792ef9e7",
   "metadata": {},
   "source": [
    "### 5. Compile the Vertex AI Pipeline into a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb6ecfbc-dcad-4848-9acf-de6687c91701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing fnSparkMlopsPipelineWithoutCaching\n"
     ]
    }
   ],
   "source": [
    "if WITHOUT_TASK_CACHING:\n",
    "    compiler.Compiler().compile(pipeline_func=fnSparkMlopsPipelineWithoutCaching, package_path=PIPELINE_PACKAGE_SRC_LOCAL_PATH)\n",
    "    print(\"Executing fnSparkMlopsPipelineWithoutCaching\")\n",
    "else:\n",
    "    compiler.Compiler().compile(pipeline_func=fnSparkMlopsPipeline, package_path=PIPELINE_PACKAGE_SRC_LOCAL_PATH)\n",
    "    print(\"Executing fnSparkMlopsPipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f665f0d-7a95-4dfb-b210-a959a3a3f914",
   "metadata": {},
   "source": [
    "### 6. Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "156f8be4-5369-4078-8191-96ca42eeb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = vertex_ai.PipelineJob(\n",
    "    display_name=PIPELINE_NM,\n",
    "    template_path=PIPELINE_PACKAGE_SRC_LOCAL_PATH,\n",
    "    pipeline_root=PIPELINE_ROOT_GCS_URI,\n",
    "    enable_caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd619ec-ecf7-4318-991a-b9330c1f51e3",
   "metadata": {},
   "source": [
    "### 7. Submit the Pipeline for execution\n",
    "There are two options below, one that uses the customer specified network that is peered with Vertex AI tenant network, and one that uses Vertex AI tenant network altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93c96b7f-ab01-4546-9eec-d53aa1800c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/569379262211/locations/us-central1/pipelineJobs/customer-churn-model-pipeline-20220930203333\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/569379262211/locations/us-central1/pipelineJobs/customer-churn-model-pipeline-20220930203333')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/customer-churn-model-pipeline-20220930203333?project=569379262211\n"
     ]
    }
   ],
   "source": [
    "if BYO_NETWORK:\n",
    "    pipeline.submit(service_account=UMSA_FQN, network=f\"projects/{PROJECT_NBR}/global/networks/{VPC_NM}\")\n",
    "else:\n",
    "    pipeline.submit(service_account=UMSA_FQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b5e66-c87a-40d1-b607-80a40260c07c",
   "metadata": {},
   "source": [
    "### 8. How do we automate this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5de77-129a-411e-89bf-5d34cba0895b",
   "metadata": {},
   "source": [
    "To automate this, we will take the compiled JSON, (1) test run it via Vertex AI Cloud Console UI, and then (2) schedule with Cloud Scheduler (calls Cloud Function that calls the Vertex AI REST endpoint for the Vertex AI pipeline).<br>This is a lab module that you can proceed to next.<br>\n",
    "Note: The json below has your project details. The lab author has a de-identified version with placeholders for your information in the git repo ../04-templates/\\*.json and as part of the Terraform automation, a customized version except custom pipeline ID is placed in 05-pipelines in your local directory in cloud shell. A copy of it is placed in GCS -> s8s-pipelines-bucket-YOUR_PROJECT_NUMBER/templates. At scheduled run time, a new custom pipeline ID is generated in the cloud function, and substituted in the json and placed in the bucket - s8s-pipelines-bucket-YOUR_PROJECT_NUMBER/execution and this is used to launch the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3eadd022-cd68-4ab4-9be7-bcf7a2e4f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-condition-aupr-threshold-exceeded-1\": {\n",
      "        \"dag\": {\n",
      "          \"tasks\": {\n",
      "            \"dataproc-create-pyspark-batch-3\": {\n",
      "              \"cachingOptions\": {},\n",
      "              \"componentRef\": {\n",
      "                \"name\": \"comp-dataproc-create-pyspark-batch-3\"\n",
      "              },\n",
      "              \"inputs\": {\n",
      "                \"parameters\": {\n",
      "                  \"archive_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"args\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_args\"\n",
      "                  },\n",
      "                  \"batch_id\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\"\n",
      "                  },\n",
      "                  \"container_image\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--container_image\"\n",
      "                  },\n",
      "                  \"file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"jar_file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"kms_key\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"labels\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"location\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--location\"\n",
      "                  },\n",
      "                  \"main_python_file_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_main_py_fqn\"\n",
      "                  },\n",
      "                  \"metastore_service\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_tags\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_uri\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"project\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--project_id\"\n",
      "                  },\n",
      "                  \"python_file_uris\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--common_utils_py_fqn\"\n",
      "                  },\n",
      "                  \"runtime_config_properties\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_runtime_config_properties\"\n",
      "                  },\n",
      "                  \"runtime_config_version\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"service_account\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--service_account\"\n",
      "                  },\n",
      "                  \"spark_history_dataproc_cluster\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--spark_phs_nm\"\n",
      "                  },\n",
      "                  \"subnetwork_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--subnetwork_uri\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"taskInfo\": {\n",
      "                \"name\": \"Hyperparameter tuning\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"pipelineparam--common_utils_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--project_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--spark_phs_nm\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--threshold\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-2\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-2\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-3\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-3\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-fnevaluatemodel\": {\n",
      "        \"executorLabel\": \"exec-fnevaluatemodel\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"metricsUri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Metrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"plots\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-tabular-dataset-create\": {\n",
      "        \"executorLabel\": \"exec-tabular-dataset-create\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"bq_source\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"display_name\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"dataset\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"google.VertexDataset\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"deploymentSpec\": {\n",
      "      \"executors\": {\n",
      "        \"exec-dataproc-create-pyspark-batch\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-2\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-3\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-fnevaluatemodel\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"fnEvaluateModel\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-c\",\n",
      "              \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'numpy==1.21.2' 'pandas==1.3.3' 'scikit-learn==0.24.2' 'kfp==1.8.11' && \\\"$0\\\" \\\"$@\\\"\\n\",\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path/ephemeral_component.py\\\"\\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp.v2 import dsl\\nfrom kfp.v2.dsl import *\\nfrom typing import *\\n\\ndef fnEvaluateModel(\\n    metricsUri: str,\\n    metrics: Output[Metrics],\\n    plots: Output[ClassificationMetrics],\\n) -> NamedTuple(\\\"Outputs\\\", [(\\\"threshold_metric\\\", float)]):\\n\\n    import json\\n    import numpy as np\\n    from sklearn.metrics import confusion_matrix, roc_curve\\n\\n    # Variables\\n    metricsGCSMountPath = metricsUri.replace(\\\"gs://\\\", \\\"/gcs/\\\")\\n    labels = [\\\"yes\\\", \\\"no\\\"]\\n\\n    # Helpers\\n    def fnCalculateROC(metrics, true, score):\\n        y_true_np = np.array(metrics[true])\\n        y_score_np = np.array(metrics[score])\\n        fpr, tpr, thresholds = roc_curve(\\n            y_true=y_true_np, y_score=y_score_np, pos_label=True\\n        )\\n        return fpr, tpr, thresholds\\n\\n    def fnCalculateConfusionMatrix(metrics, true, prediction):\\n        y_true_np = np.array(metrics[true])\\n        y_pred_np = np.array(metrics[prediction])\\n        c_matrix = confusion_matrix(y_true_np, y_pred_np)\\n        return c_matrix\\n\\n    # Main\\n    with open(metricsGCSMountPath, mode=\\\"r\\\") as json_file:\\n        metricsDictionary = json.load(json_file)\\n\\n    area_roc = metricsDictionary[\\\"test_area_roc\\\"]\\n    area_prc = metricsDictionary[\\\"test_area_prc\\\"]\\n    acc = metricsDictionary[\\\"test_accuracy\\\"]\\n    f1 = metricsDictionary[\\\"test_f1\\\"]\\n    prec = metricsDictionary[\\\"test_precision\\\"]\\n    rec = metricsDictionary[\\\"test_recall\\\"]\\n\\n    metrics.log_metric(\\\"Test_areaUnderROC\\\", area_roc)\\n    metrics.log_metric(\\\"Test_areaUnderPRC\\\", area_prc)\\n    metrics.log_metric(\\\"Test_Accuracy\\\", acc)\\n    metrics.log_metric(\\\"Test_f1-score\\\", f1)\\n    metrics.log_metric(\\\"Test_Precision\\\", prec)\\n    metrics.log_metric(\\\"Test_Recall\\\", rec)\\n\\n    fpr, tpr, thresholds = fnCalculateROC(metricsDictionary, \\\"true\\\", \\\"score\\\")\\n    c_matrix = fnCalculateConfusionMatrix(metricsDictionary, \\\"true\\\", \\\"prediction\\\")\\n    plots.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\\n    plots.log_confusion_matrix(labels, c_matrix.tolist())\\n\\n    componentOutputsTuple = NamedTuple(\\n        \\\"Outputs\\\",\\n        [\\n            (\\\"threshold_metric\\\", float),\\n        ],\\n    )\\n    return componentOutputsTuple(area_prc)\\n\\n\"\n",
      "            ],\n",
      "            \"image\": \"python:3.8\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-tabular-dataset-create\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--method.project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--method.location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--method.display_name\",\n",
      "              \"{{$.inputs.parameters['display_name']}}\",\n",
      "              \"--method.bq_source\",\n",
      "              \"{{$.inputs.parameters['bq_source']}}\",\n",
      "              \"--method.labels\",\n",
      "              \"{{$.inputs.parameters['labels']}}\",\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--resource_name_output_artifact_uri\",\n",
      "              \"{{$.outputs.artifacts['dataset'].uri}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.aiplatform.remote_runner\",\n",
      "              \"--cls_name\",\n",
      "              \"TabularDataset\",\n",
      "              \"--method_name\",\n",
      "              \"create\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"pipelineInfo\": {\n",
      "      \"name\": \"customer-churn-model-pipeline\"\n",
      "    },\n",
      "    \"root\": {\n",
      "      \"dag\": {\n",
      "        \"outputs\": {\n",
      "          \"artifacts\": {\n",
      "            \"fnevaluatemodel-metrics\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"metrics\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"fnevaluatemodel-plots\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"plots\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"tasks\": {\n",
      "          \"condition-AUPR Threshold Exceeded-1\": {\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-condition-aupr-threshold-exceeded-1\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"fnevaluatemodel\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"pipelineparam--common_utils_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"outputParameterKey\": \"threshold_metric\",\n",
      "                    \"producerTask\": \"fnevaluatemodel\"\n",
      "                  }\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_args\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_main_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_pyspark_batch_id\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_runtime_config_properties\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_runtime_config_properties\"\n",
      "                },\n",
      "                \"pipelineparam--location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"pipelineparam--project_id\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"pipelineparam--service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"pipelineparam--spark_phs_nm\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"pipelineparam--subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                },\n",
      "                \"pipelineparam--threshold\": {\n",
      "                  \"componentInputParameter\": \"threshold\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"condition-AUPR Threshold Exceeded-1\"\n",
      "            },\n",
      "            \"triggerPolicy\": {\n",
      "              \"condition\": \"inputs.parameters['pipelineparam--fnevaluatemodel-threshold_metric'].double_value >= inputs.parameters['pipelineparam--threshold'].double_value\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Preprocessing\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch-2\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch-2\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"model_training_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"model_training_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"model_training_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Model training\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-fnevaluatemodel\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch-2\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"metricsUri\": {\n",
      "                  \"componentInputParameter\": \"model_training_metrics_fqp\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Evaluate model\"\n",
      "            }\n",
      "          },\n",
      "          \"tabular-dataset-create\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-tabular-dataset-create\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"bq_source\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_src_uri\"\n",
      "                },\n",
      "                \"display_name\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_display_nm\"\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Dataset registration\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"inputDefinitions\": {\n",
      "        \"parameters\": {\n",
      "          \"common_utils_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"container_image\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_runtime_config_properties\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_display_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_src_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"project_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"service_account\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"spark_phs_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"subnetwork_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"threshold\": {\n",
      "            \"type\": \"DOUBLE\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"outputDefinitions\": {\n",
      "        \"artifacts\": {\n",
      "          \"fnevaluatemodel-metrics\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.Metrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel-plots\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"schemaVersion\": \"2.0.0\",\n",
      "    \"sdkVersion\": \"kfp-1.8.11\"\n",
      "  },\n",
      "  \"runtimeConfig\": {\n",
      "    \"parameters\": {\n",
      "      \"common_utils_py_fqn\": {\n",
      "        \"stringValue\": \"[\\\"gs://s8s_code_bucket-569379262211/pyspark/common_utils.py\\\"]\"\n",
      "      },\n",
      "      \"container_image\": {\n",
      "        \"stringValue\": \"gcr.io/gcp-scalable-ml-workshop/customer_churn_image:1.0.0\"\n",
      "      },\n",
      "      \"data_preprocessing_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2593\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"data_preprocessing_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\"\n",
      "      },\n",
      "      \"data_preprocessing_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-preprocessing-2593\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2593\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/hyperparameter_tuning.py\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/2593/full/metrics.json\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-hyperparameter-tuning-2593\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_runtime_config_properties\": {\n",
      "        \"stringValue\": \"{\\\"spark.jars.packages\\\": \\\"ml.combust.mleap:mleap-spark-base_2.12:0.20.0,ml.combust.mleap:mleap-spark_2.12:0.20.0\\\"}\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"stringValue\": \"us-central1\"\n",
      "      },\n",
      "      \"managed_dataset_display_nm\": {\n",
      "        \"stringValue\": \"customer-churn-model-2593\"\n",
      "      },\n",
      "      \"managed_dataset_src_uri\": {\n",
      "        \"stringValue\": \"bq://gcp-scalable-ml-workshop.customer_churn_ds.training_data\"\n",
      "      },\n",
      "      \"model_training_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2593\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"model_training_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/model_training.py\"\n",
      "      },\n",
      "      \"model_training_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/2593/full/metrics.json\"\n",
      "      },\n",
      "      \"model_training_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-training-2593\"\n",
      "      },\n",
      "      \"project_id\": {\n",
      "        \"stringValue\": \"gcp-scalable-ml-workshop\"\n",
      "      },\n",
      "      \"service_account\": {\n",
      "        \"stringValue\": \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "      },\n",
      "      \"spark_phs_nm\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/clusters/s8s-sphs-569379262211\"\n",
      "      },\n",
      "      \"subnetwork_uri\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/subnetworks/spark-snet\"\n",
      "      },\n",
      "      \"threshold\": {\n",
      "        \"doubleValue\": 0.5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-condition-aupr-threshold-exceeded-1\": {\n",
      "        \"dag\": {\n",
      "          \"tasks\": {\n",
      "            \"dataproc-create-pyspark-batch-3\": {\n",
      "              \"cachingOptions\": {},\n",
      "              \"componentRef\": {\n",
      "                \"name\": \"comp-dataproc-create-pyspark-batch-3\"\n",
      "              },\n",
      "              \"inputs\": {\n",
      "                \"parameters\": {\n",
      "                  \"archive_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"args\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_args\"\n",
      "                  },\n",
      "                  \"batch_id\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\"\n",
      "                  },\n",
      "                  \"container_image\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--container_image\"\n",
      "                  },\n",
      "                  \"file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"jar_file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"kms_key\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"labels\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"location\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--location\"\n",
      "                  },\n",
      "                  \"main_python_file_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_main_py_fqn\"\n",
      "                  },\n",
      "                  \"metastore_service\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_tags\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_uri\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"project\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--project_id\"\n",
      "                  },\n",
      "                  \"python_file_uris\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--common_utils_py_fqn\"\n",
      "                  },\n",
      "                  \"runtime_config_properties\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"runtime_config_version\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"service_account\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--service_account\"\n",
      "                  },\n",
      "                  \"spark_history_dataproc_cluster\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--spark_phs_nm\"\n",
      "                  },\n",
      "                  \"subnetwork_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--subnetwork_uri\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"taskInfo\": {\n",
      "                \"name\": \"Hyperparameter tuning\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"pipelineparam--common_utils_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--project_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--spark_phs_nm\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--threshold\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-2\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-2\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-3\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-3\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-fnevaluatemodel\": {\n",
      "        \"executorLabel\": \"exec-fnevaluatemodel\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"metricsUri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Metrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"plots\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-tabular-dataset-create\": {\n",
      "        \"executorLabel\": \"exec-tabular-dataset-create\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"bq_source\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"display_name\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"dataset\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"google.VertexDataset\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"deploymentSpec\": {\n",
      "      \"executors\": {\n",
      "        \"exec-dataproc-create-pyspark-batch\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-2\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-3\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-fnevaluatemodel\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"fnEvaluateModel\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-c\",\n",
      "              \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'numpy==1.21.2' 'pandas==1.3.3' 'scikit-learn==0.24.2' 'kfp==1.8.11' && \\\"$0\\\" \\\"$@\\\"\\n\",\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path/ephemeral_component.py\\\"\\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp.v2 import dsl\\nfrom kfp.v2.dsl import *\\nfrom typing import *\\n\\ndef fnEvaluateModel(\\n    metricsUri: str,\\n    metrics: Output[Metrics],\\n    plots: Output[ClassificationMetrics],\\n) -> NamedTuple(\\\"Outputs\\\", [(\\\"threshold_metric\\\", float)]):\\n\\n    import json\\n    import numpy as np\\n    from sklearn.metrics import confusion_matrix, roc_curve\\n\\n    # Variables\\n    metricsGCSMountPath = metricsUri.replace(\\\"gs://\\\", \\\"/gcs/\\\")\\n    labels = [\\\"yes\\\", \\\"no\\\"]\\n\\n    # Helpers\\n    def fnCalculateROC(metrics, true, score):\\n        y_true_np = np.array(metrics[true])\\n        y_score_np = np.array(metrics[score])\\n        fpr, tpr, thresholds = roc_curve(\\n            y_true=y_true_np, y_score=y_score_np, pos_label=True\\n        )\\n        return fpr, tpr, thresholds\\n\\n    def fnCalculateConfusionMatrix(metrics, true, prediction):\\n        y_true_np = np.array(metrics[true])\\n        y_pred_np = np.array(metrics[prediction])\\n        c_matrix = confusion_matrix(y_true_np, y_pred_np)\\n        return c_matrix\\n\\n    # Main\\n    with open(metricsGCSMountPath, mode=\\\"r\\\") as json_file:\\n        metricsDictionary = json.load(json_file)\\n\\n    area_roc = metricsDictionary[\\\"test_area_roc\\\"]\\n    area_prc = metricsDictionary[\\\"test_area_prc\\\"]\\n    acc = metricsDictionary[\\\"test_accuracy\\\"]\\n    f1 = metricsDictionary[\\\"test_f1\\\"]\\n    prec = metricsDictionary[\\\"test_precision\\\"]\\n    rec = metricsDictionary[\\\"test_recall\\\"]\\n\\n    metrics.log_metric(\\\"Test_areaUnderROC\\\", area_roc)\\n    metrics.log_metric(\\\"Test_areaUnderPRC\\\", area_prc)\\n    metrics.log_metric(\\\"Test_Accuracy\\\", acc)\\n    metrics.log_metric(\\\"Test_f1-score\\\", f1)\\n    metrics.log_metric(\\\"Test_Precision\\\", prec)\\n    metrics.log_metric(\\\"Test_Recall\\\", rec)\\n\\n    fpr, tpr, thresholds = fnCalculateROC(metricsDictionary, \\\"true\\\", \\\"score\\\")\\n    c_matrix = fnCalculateConfusionMatrix(metricsDictionary, \\\"true\\\", \\\"prediction\\\")\\n    plots.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\\n    plots.log_confusion_matrix(labels, c_matrix.tolist())\\n\\n    componentOutputsTuple = NamedTuple(\\n        \\\"Outputs\\\",\\n        [\\n            (\\\"threshold_metric\\\", float),\\n        ],\\n    )\\n    return componentOutputsTuple(area_prc)\\n\\n\"\n",
      "            ],\n",
      "            \"image\": \"python:3.8\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-tabular-dataset-create\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--method.project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--method.location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--method.display_name\",\n",
      "              \"{{$.inputs.parameters['display_name']}}\",\n",
      "              \"--method.bq_source\",\n",
      "              \"{{$.inputs.parameters['bq_source']}}\",\n",
      "              \"--method.labels\",\n",
      "              \"{{$.inputs.parameters['labels']}}\",\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--resource_name_output_artifact_uri\",\n",
      "              \"{{$.outputs.artifacts['dataset'].uri}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.aiplatform.remote_runner\",\n",
      "              \"--cls_name\",\n",
      "              \"TabularDataset\",\n",
      "              \"--method_name\",\n",
      "              \"create\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"pipelineInfo\": {\n",
      "      \"name\": \"customer-churn-model-pipeline\"\n",
      "    },\n",
      "    \"root\": {\n",
      "      \"dag\": {\n",
      "        \"outputs\": {\n",
      "          \"artifacts\": {\n",
      "            \"fnevaluatemodel-metrics\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"metrics\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"fnevaluatemodel-plots\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"plots\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"tasks\": {\n",
      "          \"condition-AUPR Threshold Exceeded-1\": {\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-condition-aupr-threshold-exceeded-1\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"fnevaluatemodel\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"pipelineparam--common_utils_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"outputParameterKey\": \"threshold_metric\",\n",
      "                    \"producerTask\": \"fnevaluatemodel\"\n",
      "                  }\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_args\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_main_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_pyspark_batch_id\"\n",
      "                },\n",
      "                \"pipelineparam--location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"pipelineparam--project_id\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"pipelineparam--service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"pipelineparam--spark_phs_nm\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"pipelineparam--subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                },\n",
      "                \"pipelineparam--threshold\": {\n",
      "                  \"componentInputParameter\": \"threshold\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"condition-AUPR Threshold Exceeded-1\"\n",
      "            },\n",
      "            \"triggerPolicy\": {\n",
      "              \"condition\": \"inputs.parameters['pipelineparam--fnevaluatemodel-threshold_metric'].double_value >= inputs.parameters['pipelineparam--threshold'].double_value\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Preprocessing\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch-2\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch-2\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"model_training_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"model_training_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"model_training_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Model training\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-fnevaluatemodel\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch-2\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"metricsUri\": {\n",
      "                  \"componentInputParameter\": \"model_training_metrics_fqp\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Evaluate model\"\n",
      "            }\n",
      "          },\n",
      "          \"tabular-dataset-create\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-tabular-dataset-create\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"bq_source\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_src_uri\"\n",
      "                },\n",
      "                \"display_name\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_display_nm\"\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Dataset registration\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"inputDefinitions\": {\n",
      "        \"parameters\": {\n",
      "          \"common_utils_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"container_image\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_display_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_src_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"project_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"service_account\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"spark_phs_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"subnetwork_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"threshold\": {\n",
      "            \"type\": \"DOUBLE\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"outputDefinitions\": {\n",
      "        \"artifacts\": {\n",
      "          \"fnevaluatemodel-metrics\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.Metrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel-plots\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"schemaVersion\": \"2.0.0\",\n",
      "    \"sdkVersion\": \"kfp-1.8.11\"\n",
      "  },\n",
      "  \"runtimeConfig\": {\n",
      "    \"parameters\": {\n",
      "      \"common_utils_py_fqn\": {\n",
      "        \"stringValue\": \"[\\\"gs://s8s_code_bucket-569379262211/pyspark/common_utils.py\\\"]\"\n",
      "      },\n",
      "      \"container_image\": {\n",
      "        \"stringValue\": \"gcr.io/gcp-scalable-ml-workshop/customer_churn_image:1.0.0\"\n",
      "      },\n",
      "      \"data_preprocessing_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2828\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"data_preprocessing_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\"\n",
      "      },\n",
      "      \"data_preprocessing_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-preprocessing-2828\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2828\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/hyperparameter_tuning.py\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/2828/full/metrics.json\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-hyperparameter-tuning-2828\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"stringValue\": \"us-central1\"\n",
      "      },\n",
      "      \"managed_dataset_display_nm\": {\n",
      "        \"stringValue\": \"customer-churn-model-2828\"\n",
      "      },\n",
      "      \"managed_dataset_src_uri\": {\n",
      "        \"stringValue\": \"bq://gcp-scalable-ml-workshop.customer_churn_ds.training_data\"\n",
      "      },\n",
      "      \"model_training_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=2828\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"model_training_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/model_training.py\"\n",
      "      },\n",
      "      \"model_training_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/2828/full/metrics.json\"\n",
      "      },\n",
      "      \"model_training_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-training-2828\"\n",
      "      },\n",
      "      \"project_id\": {\n",
      "        \"stringValue\": \"gcp-scalable-ml-workshop\"\n",
      "      },\n",
      "      \"service_account\": {\n",
      "        \"stringValue\": \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "      },\n",
      "      \"spark_phs_nm\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/clusters/s8s-sphs-569379262211\"\n",
      "      },\n",
      "      \"subnetwork_uri\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/subnetworks/spark-snet\"\n",
      "      },\n",
      "      \"threshold\": {\n",
      "        \"doubleValue\": 0.5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-condition-aupr-threshold-exceeded-1\": {\n",
      "        \"dag\": {\n",
      "          \"tasks\": {\n",
      "            \"dataproc-create-pyspark-batch-3\": {\n",
      "              \"cachingOptions\": {},\n",
      "              \"componentRef\": {\n",
      "                \"name\": \"comp-dataproc-create-pyspark-batch-3\"\n",
      "              },\n",
      "              \"inputs\": {\n",
      "                \"parameters\": {\n",
      "                  \"archive_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"args\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_args\"\n",
      "                  },\n",
      "                  \"batch_id\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\"\n",
      "                  },\n",
      "                  \"container_image\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--container_image\"\n",
      "                  },\n",
      "                  \"file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"jar_file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"kms_key\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"labels\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"location\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--location\"\n",
      "                  },\n",
      "                  \"main_python_file_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_main_py_fqn\"\n",
      "                  },\n",
      "                  \"metastore_service\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_tags\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_uri\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"project\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--project_id\"\n",
      "                  },\n",
      "                  \"python_file_uris\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--common_utils_py_fqn\"\n",
      "                  },\n",
      "                  \"runtime_config_properties\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_runtime_config_properties\"\n",
      "                  },\n",
      "                  \"runtime_config_version\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"service_account\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--service_account\"\n",
      "                  },\n",
      "                  \"spark_history_dataproc_cluster\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--spark_phs_nm\"\n",
      "                  },\n",
      "                  \"subnetwork_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--subnetwork_uri\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"taskInfo\": {\n",
      "                \"name\": \"Hyperparameter tuning\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"pipelineparam--common_utils_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--project_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--spark_phs_nm\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--threshold\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-2\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-2\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-3\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-3\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-fnevaluatemodel\": {\n",
      "        \"executorLabel\": \"exec-fnevaluatemodel\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"metricsUri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Metrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"plots\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-tabular-dataset-create\": {\n",
      "        \"executorLabel\": \"exec-tabular-dataset-create\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"bq_source\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"display_name\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"dataset\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"google.VertexDataset\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"deploymentSpec\": {\n",
      "      \"executors\": {\n",
      "        \"exec-dataproc-create-pyspark-batch\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-2\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-3\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-fnevaluatemodel\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"fnEvaluateModel\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-c\",\n",
      "              \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'numpy==1.21.2' 'pandas==1.3.3' 'scikit-learn==0.24.2' 'kfp==1.8.11' && \\\"$0\\\" \\\"$@\\\"\\n\",\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path/ephemeral_component.py\\\"\\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp.v2 import dsl\\nfrom kfp.v2.dsl import *\\nfrom typing import *\\n\\ndef fnEvaluateModel(\\n    metricsUri: str,\\n    metrics: Output[Metrics],\\n    plots: Output[ClassificationMetrics],\\n) -> NamedTuple(\\\"Outputs\\\", [(\\\"threshold_metric\\\", float)]):\\n\\n    import json\\n    import numpy as np\\n    from sklearn.metrics import confusion_matrix, roc_curve\\n\\n    # Variables\\n    metricsGCSMountPath = metricsUri.replace(\\\"gs://\\\", \\\"/gcs/\\\")\\n    labels = [\\\"yes\\\", \\\"no\\\"]\\n\\n    # Helpers\\n    def fnCalculateROC(metrics, true, score):\\n        y_true_np = np.array(metrics[true])\\n        y_score_np = np.array(metrics[score])\\n        fpr, tpr, thresholds = roc_curve(\\n            y_true=y_true_np, y_score=y_score_np, pos_label=True\\n        )\\n        return fpr, tpr, thresholds\\n\\n    def fnCalculateConfusionMatrix(metrics, true, prediction):\\n        y_true_np = np.array(metrics[true])\\n        y_pred_np = np.array(metrics[prediction])\\n        c_matrix = confusion_matrix(y_true_np, y_pred_np)\\n        return c_matrix\\n\\n    # Main\\n    with open(metricsGCSMountPath, mode=\\\"r\\\") as json_file:\\n        metricsDictionary = json.load(json_file)\\n\\n    area_roc = metricsDictionary[\\\"test_area_roc\\\"]\\n    area_prc = metricsDictionary[\\\"test_area_prc\\\"]\\n    acc = metricsDictionary[\\\"test_accuracy\\\"]\\n    f1 = metricsDictionary[\\\"test_f1\\\"]\\n    prec = metricsDictionary[\\\"test_precision\\\"]\\n    rec = metricsDictionary[\\\"test_recall\\\"]\\n\\n    metrics.log_metric(\\\"Test_areaUnderROC\\\", area_roc)\\n    metrics.log_metric(\\\"Test_areaUnderPRC\\\", area_prc)\\n    metrics.log_metric(\\\"Test_Accuracy\\\", acc)\\n    metrics.log_metric(\\\"Test_f1-score\\\", f1)\\n    metrics.log_metric(\\\"Test_Precision\\\", prec)\\n    metrics.log_metric(\\\"Test_Recall\\\", rec)\\n\\n    fpr, tpr, thresholds = fnCalculateROC(metricsDictionary, \\\"true\\\", \\\"score\\\")\\n    c_matrix = fnCalculateConfusionMatrix(metricsDictionary, \\\"true\\\", \\\"prediction\\\")\\n    plots.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\\n    plots.log_confusion_matrix(labels, c_matrix.tolist())\\n\\n    componentOutputsTuple = NamedTuple(\\n        \\\"Outputs\\\",\\n        [\\n            (\\\"threshold_metric\\\", float),\\n        ],\\n    )\\n    return componentOutputsTuple(area_prc)\\n\\n\"\n",
      "            ],\n",
      "            \"image\": \"python:3.8\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-tabular-dataset-create\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--method.project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--method.location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--method.display_name\",\n",
      "              \"{{$.inputs.parameters['display_name']}}\",\n",
      "              \"--method.bq_source\",\n",
      "              \"{{$.inputs.parameters['bq_source']}}\",\n",
      "              \"--method.labels\",\n",
      "              \"{{$.inputs.parameters['labels']}}\",\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--resource_name_output_artifact_uri\",\n",
      "              \"{{$.outputs.artifacts['dataset'].uri}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.aiplatform.remote_runner\",\n",
      "              \"--cls_name\",\n",
      "              \"TabularDataset\",\n",
      "              \"--method_name\",\n",
      "              \"create\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"pipelineInfo\": {\n",
      "      \"name\": \"customer-churn-model-pipeline\"\n",
      "    },\n",
      "    \"root\": {\n",
      "      \"dag\": {\n",
      "        \"outputs\": {\n",
      "          \"artifacts\": {\n",
      "            \"fnevaluatemodel-metrics\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"metrics\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"fnevaluatemodel-plots\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"plots\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"tasks\": {\n",
      "          \"condition-AUPR Threshold Exceeded-1\": {\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-condition-aupr-threshold-exceeded-1\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"fnevaluatemodel\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"pipelineparam--common_utils_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"outputParameterKey\": \"threshold_metric\",\n",
      "                    \"producerTask\": \"fnevaluatemodel\"\n",
      "                  }\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_args\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_main_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_pyspark_batch_id\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_runtime_config_properties\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_runtime_config_properties\"\n",
      "                },\n",
      "                \"pipelineparam--location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"pipelineparam--project_id\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"pipelineparam--service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"pipelineparam--spark_phs_nm\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"pipelineparam--subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                },\n",
      "                \"pipelineparam--threshold\": {\n",
      "                  \"componentInputParameter\": \"threshold\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"condition-AUPR Threshold Exceeded-1\"\n",
      "            },\n",
      "            \"triggerPolicy\": {\n",
      "              \"condition\": \"inputs.parameters['pipelineparam--fnevaluatemodel-threshold_metric'].double_value >= inputs.parameters['pipelineparam--threshold'].double_value\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Preprocessing\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch-2\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch-2\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"model_training_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"model_training_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"model_training_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Model training\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-fnevaluatemodel\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch-2\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"metricsUri\": {\n",
      "                  \"componentInputParameter\": \"model_training_metrics_fqp\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Evaluate model\"\n",
      "            }\n",
      "          },\n",
      "          \"tabular-dataset-create\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-tabular-dataset-create\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"bq_source\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_src_uri\"\n",
      "                },\n",
      "                \"display_name\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_display_nm\"\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Dataset registration\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"inputDefinitions\": {\n",
      "        \"parameters\": {\n",
      "          \"common_utils_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"container_image\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_runtime_config_properties\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_display_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_src_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"project_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"service_account\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"spark_phs_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"subnetwork_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"threshold\": {\n",
      "            \"type\": \"DOUBLE\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"outputDefinitions\": {\n",
      "        \"artifacts\": {\n",
      "          \"fnevaluatemodel-metrics\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.Metrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel-plots\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"schemaVersion\": \"2.0.0\",\n",
      "    \"sdkVersion\": \"kfp-1.8.11\"\n",
      "  },\n",
      "  \"runtimeConfig\": {\n",
      "    \"parameters\": {\n",
      "      \"common_utils_py_fqn\": {\n",
      "        \"stringValue\": \"[\\\"gs://s8s_code_bucket-569379262211/pyspark/common_utils.py\\\"]\"\n",
      "      },\n",
      "      \"container_image\": {\n",
      "        \"stringValue\": \"gcr.io/gcp-scalable-ml-workshop/customer_churn_image:1.0.0\"\n",
      "      },\n",
      "      \"data_preprocessing_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=321\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"data_preprocessing_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\"\n",
      "      },\n",
      "      \"data_preprocessing_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-preprocessing-321\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=321\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/hyperparameter_tuning.py\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/321/full/metrics.json\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-hyperparameter-tuning-321\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_runtime_config_properties\": {\n",
      "        \"stringValue\": \"{\\\"spark.jars.packages\\\": \\\"ml.combust.mleap:mleap-spark-base_2.12:0.20.0,ml.combust.mleap:mleap-spark_2.12:0.20.0\\\"}\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"stringValue\": \"us-central1\"\n",
      "      },\n",
      "      \"managed_dataset_display_nm\": {\n",
      "        \"stringValue\": \"customer-churn-model-321\"\n",
      "      },\n",
      "      \"managed_dataset_src_uri\": {\n",
      "        \"stringValue\": \"bq://gcp-scalable-ml-workshop.customer_churn_ds.training_data\"\n",
      "      },\n",
      "      \"model_training_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=321\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"model_training_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/model_training.py\"\n",
      "      },\n",
      "      \"model_training_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/321/full/metrics.json\"\n",
      "      },\n",
      "      \"model_training_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-training-321\"\n",
      "      },\n",
      "      \"project_id\": {\n",
      "        \"stringValue\": \"gcp-scalable-ml-workshop\"\n",
      "      },\n",
      "      \"service_account\": {\n",
      "        \"stringValue\": \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "      },\n",
      "      \"spark_phs_nm\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/clusters/s8s-sphs-569379262211\"\n",
      "      },\n",
      "      \"subnetwork_uri\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/subnetworks/spark-snet\"\n",
      "      },\n",
      "      \"threshold\": {\n",
      "        \"doubleValue\": 0.5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-condition-aupr-threshold-exceeded-1\": {\n",
      "        \"dag\": {\n",
      "          \"tasks\": {\n",
      "            \"dataproc-create-pyspark-batch-3\": {\n",
      "              \"cachingOptions\": {},\n",
      "              \"componentRef\": {\n",
      "                \"name\": \"comp-dataproc-create-pyspark-batch-3\"\n",
      "              },\n",
      "              \"inputs\": {\n",
      "                \"parameters\": {\n",
      "                  \"archive_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"args\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_args\"\n",
      "                  },\n",
      "                  \"batch_id\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\"\n",
      "                  },\n",
      "                  \"container_image\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--container_image\"\n",
      "                  },\n",
      "                  \"file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"jar_file_uris\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"kms_key\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"labels\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"location\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--location\"\n",
      "                  },\n",
      "                  \"main_python_file_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--hyperparameter_tuning_main_py_fqn\"\n",
      "                  },\n",
      "                  \"metastore_service\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_tags\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"[]\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"network_uri\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"project\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--project_id\"\n",
      "                  },\n",
      "                  \"python_file_uris\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--common_utils_py_fqn\"\n",
      "                  },\n",
      "                  \"runtime_config_properties\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"{}\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"runtime_config_version\": {\n",
      "                    \"runtimeValue\": {\n",
      "                      \"constantValue\": {\n",
      "                        \"stringValue\": \"\"\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"service_account\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--service_account\"\n",
      "                  },\n",
      "                  \"spark_history_dataproc_cluster\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--spark_phs_nm\"\n",
      "                  },\n",
      "                  \"subnetwork_uri\": {\n",
      "                    \"componentInputParameter\": \"pipelineparam--subnetwork_uri\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"taskInfo\": {\n",
      "                \"name\": \"Hyperparameter tuning\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"pipelineparam--common_utils_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--project_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--spark_phs_nm\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"pipelineparam--threshold\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-2\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-2\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-dataproc-create-pyspark-batch-3\": {\n",
      "        \"executorLabel\": \"exec-dataproc-create-pyspark-batch-3\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"archive_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"args\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"batch_id\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"container_image\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"jar_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"kms_key\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"main_python_file_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"metastore_service\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_tags\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"network_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"python_file_uris\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_properties\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"runtime_config_version\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"spark_history_dataproc_cluster\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"subnetwork_uri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-fnevaluatemodel\": {\n",
      "        \"executorLabel\": \"exec-fnevaluatemodel\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"metricsUri\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Metrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"plots\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"threshold_metric\": {\n",
      "              \"type\": \"DOUBLE\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"comp-tabular-dataset-create\": {\n",
      "        \"executorLabel\": \"exec-tabular-dataset-create\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"bq_source\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"display_name\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"labels\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"type\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"dataset\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"google.VertexDataset\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"deploymentSpec\": {\n",
      "      \"executors\": {\n",
      "        \"exec-dataproc-create-pyspark-batch\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-2\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-dataproc-create-pyspark-batch-3\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"DataprocPySparkBatch\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"labels\\\": {{$.inputs.parameters['labels']}}, \\\"runtime_config\\\": {\\\"version\\\": \\\"{{$.inputs.parameters['runtime_config_version']}}\\\", \\\"container_image\\\": \\\"{{$.inputs.parameters['container_image']}}\\\", \\\"properties\\\": {{$.inputs.parameters['runtime_config_properties']}}}, \\\"environment_config\\\": {\\\"execution_config\\\": {\\\"service_account\\\": \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"network_tags\\\": {{$.inputs.parameters['network_tags']}}, \\\"kms_key\\\": \\\"{{$.inputs.parameters['kms_key']}}\\\", \\\"network_uri\\\": \\\"{{$.inputs.parameters['network_uri']}}\\\", \\\"subnetwork_uri\\\": \\\"{{$.inputs.parameters['subnetwork_uri']}}\\\"}, \\\"peripherals_config\\\": {\\\"metastore_service\\\": \\\"{{$.inputs.parameters['metastore_service']}}\\\", \\\"spark_history_server_config\\\": { \\\"dataproc_cluster\\\": \\\"{{$.inputs.parameters['spark_history_dataproc_cluster']}}\\\"}}}, \\\"pyspark_batch\\\": {\\\"main_python_file_uri\\\": \\\"{{$.inputs.parameters['main_python_file_uri']}}\\\", \\\"python_file_uris\\\": {{$.inputs.parameters['python_file_uris']}}, \\\"jar_file_uris\\\": {{$.inputs.parameters['jar_file_uris']}}, \\\"file_uris\\\": {{$.inputs.parameters['file_uris']}}, \\\"archive_uris\\\": {{$.inputs.parameters['archive_uris']}}, \\\"args\\\": {{$.inputs.parameters['args']}}}}\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--batch_id\",\n",
      "              \"{{$.inputs.parameters['batch_id']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.gcp_launcher.launcher\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-fnevaluatemodel\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"fnEvaluateModel\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-c\",\n",
      "              \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'numpy==1.21.2' 'pandas==1.3.3' 'scikit-learn==0.24.2' 'kfp==1.8.11' && \\\"$0\\\" \\\"$@\\\"\\n\",\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path/ephemeral_component.py\\\"\\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp.v2 import dsl\\nfrom kfp.v2.dsl import *\\nfrom typing import *\\n\\ndef fnEvaluateModel(\\n    metricsUri: str,\\n    metrics: Output[Metrics],\\n    plots: Output[ClassificationMetrics],\\n) -> NamedTuple(\\\"Outputs\\\", [(\\\"threshold_metric\\\", float)]):\\n\\n    import json\\n    import numpy as np\\n    from sklearn.metrics import confusion_matrix, roc_curve\\n\\n    # Variables\\n    metricsGCSMountPath = metricsUri.replace(\\\"gs://\\\", \\\"/gcs/\\\")\\n    labels = [\\\"yes\\\", \\\"no\\\"]\\n\\n    # Helpers\\n    def fnCalculateROC(metrics, true, score):\\n        y_true_np = np.array(metrics[true])\\n        y_score_np = np.array(metrics[score])\\n        fpr, tpr, thresholds = roc_curve(\\n            y_true=y_true_np, y_score=y_score_np, pos_label=True\\n        )\\n        return fpr, tpr, thresholds\\n\\n    def fnCalculateConfusionMatrix(metrics, true, prediction):\\n        y_true_np = np.array(metrics[true])\\n        y_pred_np = np.array(metrics[prediction])\\n        c_matrix = confusion_matrix(y_true_np, y_pred_np)\\n        return c_matrix\\n\\n    # Main\\n    with open(metricsGCSMountPath, mode=\\\"r\\\") as json_file:\\n        metricsDictionary = json.load(json_file)\\n\\n    area_roc = metricsDictionary[\\\"test_area_roc\\\"]\\n    area_prc = metricsDictionary[\\\"test_area_prc\\\"]\\n    acc = metricsDictionary[\\\"test_accuracy\\\"]\\n    f1 = metricsDictionary[\\\"test_f1\\\"]\\n    prec = metricsDictionary[\\\"test_precision\\\"]\\n    rec = metricsDictionary[\\\"test_recall\\\"]\\n\\n    metrics.log_metric(\\\"Test_areaUnderROC\\\", area_roc)\\n    metrics.log_metric(\\\"Test_areaUnderPRC\\\", area_prc)\\n    metrics.log_metric(\\\"Test_Accuracy\\\", acc)\\n    metrics.log_metric(\\\"Test_f1-score\\\", f1)\\n    metrics.log_metric(\\\"Test_Precision\\\", prec)\\n    metrics.log_metric(\\\"Test_Recall\\\", rec)\\n\\n    fpr, tpr, thresholds = fnCalculateROC(metricsDictionary, \\\"true\\\", \\\"score\\\")\\n    c_matrix = fnCalculateConfusionMatrix(metricsDictionary, \\\"true\\\", \\\"prediction\\\")\\n    plots.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\\n    plots.log_confusion_matrix(labels, c_matrix.tolist())\\n\\n    componentOutputsTuple = NamedTuple(\\n        \\\"Outputs\\\",\\n        [\\n            (\\\"threshold_metric\\\", float),\\n        ],\\n    )\\n    return componentOutputsTuple(area_prc)\\n\\n\"\n",
      "            ],\n",
      "            \"image\": \"python:3.8\"\n",
      "          }\n",
      "        },\n",
      "        \"exec-tabular-dataset-create\": {\n",
      "          \"container\": {\n",
      "            \"args\": [\n",
      "              \"--method.project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--method.location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--method.display_name\",\n",
      "              \"{{$.inputs.parameters['display_name']}}\",\n",
      "              \"--method.bq_source\",\n",
      "              \"{{$.inputs.parameters['bq_source']}}\",\n",
      "              \"--method.labels\",\n",
      "              \"{{$.inputs.parameters['labels']}}\",\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--resource_name_output_artifact_uri\",\n",
      "              \"{{$.outputs.artifacts['dataset'].uri}}\"\n",
      "            ],\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.aiplatform.remote_runner\",\n",
      "              \"--cls_name\",\n",
      "              \"TabularDataset\",\n",
      "              \"--method_name\",\n",
      "              \"create\"\n",
      "            ],\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.1\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"pipelineInfo\": {\n",
      "      \"name\": \"customer-churn-model-pipeline\"\n",
      "    },\n",
      "    \"root\": {\n",
      "      \"dag\": {\n",
      "        \"outputs\": {\n",
      "          \"artifacts\": {\n",
      "            \"fnevaluatemodel-metrics\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"metrics\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"fnevaluatemodel-plots\": {\n",
      "              \"artifactSelectors\": [\n",
      "                {\n",
      "                  \"outputArtifactKey\": \"plots\",\n",
      "                  \"producerSubtask\": \"fnevaluatemodel\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"tasks\": {\n",
      "          \"condition-AUPR Threshold Exceeded-1\": {\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-condition-aupr-threshold-exceeded-1\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"fnevaluatemodel\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"pipelineparam--common_utils_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"pipelineparam--fnevaluatemodel-threshold_metric\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"outputParameterKey\": \"threshold_metric\",\n",
      "                    \"producerTask\": \"fnevaluatemodel\"\n",
      "                  }\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_args\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_args\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_main_py_fqn\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_main_py_fqn\"\n",
      "                },\n",
      "                \"pipelineparam--hyperparameter_tuning_pyspark_batch_id\": {\n",
      "                  \"componentInputParameter\": \"hyperparameter_tuning_pyspark_batch_id\"\n",
      "                },\n",
      "                \"pipelineparam--location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"pipelineparam--project_id\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"pipelineparam--service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"pipelineparam--spark_phs_nm\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"pipelineparam--subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                },\n",
      "                \"pipelineparam--threshold\": {\n",
      "                  \"componentInputParameter\": \"threshold\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"condition-AUPR Threshold Exceeded-1\"\n",
      "            },\n",
      "            \"triggerPolicy\": {\n",
      "              \"condition\": \"inputs.parameters['pipelineparam--fnevaluatemodel-threshold_metric'].double_value >= inputs.parameters['pipelineparam--threshold'].double_value\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"data_preprocessing_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Preprocessing\"\n",
      "            }\n",
      "          },\n",
      "          \"dataproc-create-pyspark-batch-2\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-dataproc-create-pyspark-batch-2\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"archive_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"args\": {\n",
      "                  \"componentInputParameter\": \"model_training_args\"\n",
      "                },\n",
      "                \"batch_id\": {\n",
      "                  \"componentInputParameter\": \"model_training_pyspark_batch_id\"\n",
      "                },\n",
      "                \"container_image\": {\n",
      "                  \"componentInputParameter\": \"container_image\"\n",
      "                },\n",
      "                \"file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"jar_file_uris\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"kms_key\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"main_python_file_uri\": {\n",
      "                  \"componentInputParameter\": \"model_training_main_py_fqn\"\n",
      "                },\n",
      "                \"metastore_service\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_tags\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"[]\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"network_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                },\n",
      "                \"python_file_uris\": {\n",
      "                  \"componentInputParameter\": \"common_utils_py_fqn\"\n",
      "                },\n",
      "                \"runtime_config_properties\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"runtime_config_version\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"service_account\": {\n",
      "                  \"componentInputParameter\": \"service_account\"\n",
      "                },\n",
      "                \"spark_history_dataproc_cluster\": {\n",
      "                  \"componentInputParameter\": \"spark_phs_nm\"\n",
      "                },\n",
      "                \"subnetwork_uri\": {\n",
      "                  \"componentInputParameter\": \"subnetwork_uri\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Model training\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-fnevaluatemodel\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch-2\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"metricsUri\": {\n",
      "                  \"componentInputParameter\": \"model_training_metrics_fqp\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Evaluate model\"\n",
      "            }\n",
      "          },\n",
      "          \"tabular-dataset-create\": {\n",
      "            \"cachingOptions\": {},\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-tabular-dataset-create\"\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"dataproc-create-pyspark-batch\"\n",
      "            ],\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"bq_source\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_src_uri\"\n",
      "                },\n",
      "                \"display_name\": {\n",
      "                  \"componentInputParameter\": \"managed_dataset_display_nm\"\n",
      "                },\n",
      "                \"labels\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constantValue\": {\n",
      "                      \"stringValue\": \"{}\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project_id\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"Dataset registration\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"inputDefinitions\": {\n",
      "        \"parameters\": {\n",
      "          \"common_utils_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"container_image\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"data_preprocessing_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_display_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"managed_dataset_src_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_args\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_main_py_fqn\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_metrics_fqp\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"model_training_pyspark_batch_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"project_id\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"service_account\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"spark_phs_nm\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"subnetwork_uri\": {\n",
      "            \"type\": \"STRING\"\n",
      "          },\n",
      "          \"threshold\": {\n",
      "            \"type\": \"DOUBLE\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"outputDefinitions\": {\n",
      "        \"artifacts\": {\n",
      "          \"fnevaluatemodel-metrics\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.Metrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          },\n",
      "          \"fnevaluatemodel-plots\": {\n",
      "            \"artifactType\": {\n",
      "              \"schemaTitle\": \"system.ClassificationMetrics\",\n",
      "              \"schemaVersion\": \"0.0.1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"schemaVersion\": \"2.0.0\",\n",
      "    \"sdkVersion\": \"kfp-1.8.11\"\n",
      "  },\n",
      "  \"runtimeConfig\": {\n",
      "    \"parameters\": {\n",
      "      \"common_utils_py_fqn\": {\n",
      "        \"stringValue\": \"[\\\"gs://s8s_code_bucket-569379262211/pyspark/common_utils.py\\\"]\"\n",
      "      },\n",
      "      \"container_image\": {\n",
      "        \"stringValue\": \"gcr.io/gcp-scalable-ml-workshop/customer_churn_image:1.0.0\"\n",
      "      },\n",
      "      \"data_preprocessing_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=4381\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"data_preprocessing_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\"\n",
      "      },\n",
      "      \"data_preprocessing_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-preprocessing-4381\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=4381\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/hyperparameter_tuning.py\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/4381/full/metrics.json\"\n",
      "      },\n",
      "      \"hyperparameter_tuning_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-hyperparameter-tuning-4381\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"stringValue\": \"us-central1\"\n",
      "      },\n",
      "      \"managed_dataset_display_nm\": {\n",
      "        \"stringValue\": \"customer-churn-model-4381\"\n",
      "      },\n",
      "      \"managed_dataset_src_uri\": {\n",
      "        \"stringValue\": \"bq://gcp-scalable-ml-workshop.customer_churn_ds.training_data\"\n",
      "      },\n",
      "      \"model_training_args\": {\n",
      "        \"stringValue\": \"[\\\"--pipelineID=4381\\\", \\\"--projectID=gcp-scalable-ml-workshop\\\", \\\"--projectNbr=569379262211\\\", \\\"--displayPrintStatements=True\\\"]\"\n",
      "      },\n",
      "      \"model_training_main_py_fqn\": {\n",
      "        \"stringValue\": \"gs://s8s_code_bucket-569379262211/pyspark/model_training.py\"\n",
      "      },\n",
      "      \"model_training_metrics_fqp\": {\n",
      "        \"stringValue\": \"gs://s8s_metrics_bucket-569379262211/customer-churn-model/training/4381/full/metrics.json\"\n",
      "      },\n",
      "      \"model_training_pyspark_batch_id\": {\n",
      "        \"stringValue\": \"customer-churn-model-training-4381\"\n",
      "      },\n",
      "      \"project_id\": {\n",
      "        \"stringValue\": \"gcp-scalable-ml-workshop\"\n",
      "      },\n",
      "      \"service_account\": {\n",
      "        \"stringValue\": \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "      },\n",
      "      \"spark_phs_nm\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/clusters/s8s-sphs-569379262211\"\n",
      "      },\n",
      "      \"subnetwork_uri\": {\n",
      "        \"stringValue\": \"projects/gcp-scalable-ml-workshop/regions/us-central1/subnetworks/spark-snet\"\n",
      "      },\n",
      "      \"threshold\": {\n",
      "        \"doubleValue\": 0.5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat $LOCAL_SCRATCH_DIR/*"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
