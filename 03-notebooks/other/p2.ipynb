{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a212fa6e-2198-41c6-9e69-8d7abb407684",
   "metadata": {},
   "source": [
    "# MLOps for Spark MLLib with Vertex AI Pipelines - Part 2\n",
    "In this notebook, we create a Vertex AI pipeline for MLOps with Spark MLLib powered by Dataproc Serverless Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46e6a9-0c11-42fe-9595-3007cfcfb0ef",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34ff675-62e7-410f-b619-f1f8d8ab0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path as path\n",
    "from typing import NamedTuple\n",
    "import os\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google_cloud_pipeline_components import aiplatform as vertex_ai_components\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import (Artifact, ClassificationMetrics, Condition, Input,\n",
    "                        Metrics, Output, component)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a129398-d241-47b8-8063-73b605a936d8",
   "metadata": {},
   "source": [
    "#### a. Project specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed589bb-8ed3-4cb0-96c4-462a310d1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  s8s-spark-ml-mlops\n",
      "Project Number:  974925525028\n",
      "UMSA FQN:  s8s-lab-sa@s8s-spark-ml-mlops.iam.gserviceaccount.com\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "PROJECT_NBR = \"\"\n",
    "UNIQUE_ID = random.randint(1, 10000)\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = project_id_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "    \n",
    "    \n",
    "    project_nbr_output = !gcloud projects describe $PROJECT_ID --format='value(projectNumber)'\n",
    "    PROJECT_NBR = project_nbr_output[0]\n",
    "    print(\"Project Number: \", PROJECT_NBR)\n",
    "    \n",
    "umsa_output = !gcloud config list account --format \"value(core.account)\"\n",
    "UMSA_FQN = umsa_output[0]\n",
    "print(\"UMSA FQN: \", UMSA_FQN)\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7b7a0-4281-4d6b-9cec-7fed2b300b44",
   "metadata": {},
   "source": [
    "#### b. The pre-created resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347c9514-0d95-47f7-9671-1c2b5ff73255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_SCRATCH_DIR = docker-build-scratch\n",
      "UMSA_FQN = s8s-lab-sa@s8s-spark-ml-mlops.iam.gserviceaccount.com\n",
      "CODE_BUCKET = gs://s8s_code_bucket-974925525028\n",
      "DATA_BUCKET = gs://s8s_data_bucket-974925525028\n",
      "MODEL_BUCKET = gs://s8s_model_bucket-974925525028\n",
      "SCRATCH_BUCKET = s8s-spark-bucket-974925525028\n",
      "LOCATION = us-central1\n",
      "VPC_NM = s8s-vpc-974925525028\n",
      "SUBNET_RESOURCE_URI = projects/s8s-spark-ml-mlops/regions/us-central1/subnetworks/spark-snet\n",
      "PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI = projects/s8s-spark-ml-mlops/regions/us-central1/clusters/s8s-sphs-974925525028\n",
      "GCR_REPO_NM = s8s-spark-974925525028\n",
      "DOCKER_IMAGE_FQN = gcr.io/s8s-spark-ml-mlops/dataproc_serverless_custom_runtime:1.0.2\n"
     ]
    }
   ],
   "source": [
    "LOCAL_SCRATCH_DIR = path(\"docker-build-scratch\")\n",
    "CODE_BUCKET = f\"gs://s8s_code_bucket-{PROJECT_NBR}\"\n",
    "DATA_BUCKET = f\"gs://s8s_data_bucket-{PROJECT_NBR}\"\n",
    "MODEL_BUCKET = f\"gs://s8s_model_bucket-{PROJECT_NBR}\"\n",
    "SCRATCH_BUCKET = f\"s8s-spark-bucket-{PROJECT_NBR}\"\n",
    "LOCATION = \"us-central1\"\n",
    "VPC_NM = f\"s8s-vpc-{PROJECT_NBR}\"\n",
    "SUBNET_RESOURCE_URI = f\"projects/{PROJECT_ID}/regions/{LOCATION}/subnetworks/spark-snet\"\n",
    "PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI = f\"projects/{PROJECT_ID}/regions/{LOCATION}/clusters/s8s-sphs-{PROJECT_NBR}\"\n",
    "GCR_REPO_NM = f\"s8s-spark-{PROJECT_NBR}\"\n",
    "DOCKER_IMAGE_TAG = \"1.0.3\"\n",
    "DOCKER_IMAGE_NM = \"dataproc_serverless_custom_runtime\"\n",
    "DOCKER_IMAGE_FQN = f\"gcr.io/{PROJECT_ID}/{DOCKER_IMAGE_NM}:{DOCKER_IMAGE_TAG}\"\n",
    "\n",
    "print('LOCAL_SCRATCH_DIR =',LOCAL_SCRATCH_DIR)\n",
    "print('UMSA_FQN =',UMSA_FQN)\n",
    "print('CODE_BUCKET =',CODE_BUCKET)\n",
    "print('DATA_BUCKET =',DATA_BUCKET)\n",
    "print('MODEL_BUCKET =',MODEL_BUCKET)\n",
    "print('SCRATCH_BUCKET =',SCRATCH_BUCKET)\n",
    "print('LOCATION =',LOCATION)\n",
    "print('VPC_NM =',VPC_NM)\n",
    "print('SUBNET_RESOURCE_URI =',SUBNET_RESOURCE_URI)\n",
    "print('PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI =',PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI)\n",
    "print('GCR_REPO_NM =',GCR_REPO_NM)\n",
    "print('DOCKER_IMAGE_FQN =',DOCKER_IMAGE_FQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab3891-5f9d-40f3-b709-80754abe8d1d",
   "metadata": {},
   "source": [
    "#### c. Pipeline entity specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6858b5a-40bd-4705-9a77-2dc3fd97eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ID = 1544\n",
      "PIPELINE_NM = pyspark-customer-churn-pipeline\n",
      "PIPELINE_PACKAGE_SRC_LOCAL_PATH = docker-build-scratch/pipeline_1544.json\n",
      "PIPELINE_ROOT_GCS_URI = gs://s8s_model_bucket-974925525028/pipelines\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_ID = UNIQUE_ID\n",
    "PIPELINE_NM = \"pyspark-customer-churn-pipeline\"\n",
    "PIPELINE_PACKAGE_SRC_LOCAL_PATH = f\"{LOCAL_SCRATCH_DIR}/pipeline_{PIPELINE_ID}.json\"\n",
    "PIPELINE_ROOT_GCS_URI = f\"{MODEL_BUCKET}/pipelines\"\n",
    "\n",
    "print('PIPELINE_ID =',PIPELINE_ID)\n",
    "print('PIPELINE_NM =',PIPELINE_NM)\n",
    "print('PIPELINE_PACKAGE_SRC_LOCAL_PATH =',PIPELINE_PACKAGE_SRC_LOCAL_PATH)\n",
    "print('PIPELINE_ROOT_GCS_URI =',PIPELINE_ROOT_GCS_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a93fba-9714-46dc-b8f7-929331c159dc",
   "metadata": {},
   "source": [
    "#### d. Pipeline stage agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c437c615-18eb-4aa1-92ef-65a6af02a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY_SCRIPTS_FQP = gs://s8s_code_bucket-974925525028/pyspark\n",
      "PYSPARK_COMMON_UTILS_SCRIPT_FQP = ['gs://s8s_code_bucket-974925525028/pyspark/common_utils.py']\n"
     ]
    }
   ],
   "source": [
    "PY_SCRIPTS_FQP = f\"{CODE_BUCKET}/pyspark\"\n",
    "PYSPARK_COMMON_UTILS_SCRIPT_FQP = [f\"{PY_SCRIPTS_FQP}/common_utils.py\"]\n",
    "\n",
    "print('PY_SCRIPTS_FQP =',PY_SCRIPTS_FQP)\n",
    "print('PYSPARK_COMMON_UTILS_SCRIPT_FQP =',PYSPARK_COMMON_UTILS_SCRIPT_FQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf673b2e-89c6-4eaf-bb8b-69b206f84814",
   "metadata": {},
   "source": [
    "#### d. Data preprocessing stage specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d881fbc3-ee62-4969-928d-55a44dd2219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PREPROCESSING_BATCH_PREFIX = customer-churn-data-preprocessing\n",
      "DATA_PREPROCESSING_BATCH_INSTANCE_ID = customer-churn-data-preprocessing-1544\n",
      "DATA_PREPROCESSING_MAIN_PY_SCRIPT = gs://s8s_code_bucket-974925525028/pyspark/data_preprocessing.py\n",
      "DATA_PREPROCESSING_RAW_SOURCE_FQP = gs://s8s_data_bucket-974925525028/customer_churn_train_data.csv\n",
      "DATA_PREPROCESSING_SCRATCH_BUCKET = s8s-spark-bucket-974925525028/customer-churn-data-preprocessing\n",
      "DATA_PREPROCESSING_ARGS = ['--appName=customer-churn-data-preprocessing', '--projectID=s8s-spark-ml-mlops', '--rawDatasetBucketFQN=gs://s8s_data_bucket-974925525028/customer_churn_train_data.csv', '--sparkBigQueryScratchBucketUri=s8s-spark-bucket-974925525028/customer-churn-data-preprocessing', '--enableDataframeDisplay=True']\n",
      "DATA_PROCESSING_BQ_SINK = s8s-spark-ml-mlops.customer_churn_ds.customer_churn_training_data\n",
      "DATA_PROCESSING_BQ_SINK_URI = bq://s8s-spark-ml-mlops.customer_churn_ds.customer_churn_training_data\n"
     ]
    }
   ],
   "source": [
    "DATA_PREPROCESSING_BATCH_PREFIX = \"customer-churn-data-preprocessing\"\n",
    "DATA_PREPROCESSING_BATCH_INSTANCE_ID = f\"{DATA_PREPROCESSING_BATCH_PREFIX}-{UNIQUE_ID}\"\n",
    "DATA_PREPROCESSING_MAIN_PY_SCRIPT = f\"{PY_SCRIPTS_FQP}/data_preprocessing.py\"\n",
    "DATA_PREPROCESSING_RAW_SOURCE_FQP = f\"{DATA_BUCKET}/customer_churn_train_data.csv\"\n",
    "DATA_PREPROCESSING_SCRATCH_BUCKET = f\"{SCRATCH_BUCKET}/{DATA_PREPROCESSING_BATCH_PREFIX}\"\n",
    "DATA_PREPROCESSING_ARGS = [f\"--appName={DATA_PREPROCESSING_BATCH_PREFIX}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--rawDatasetBucketFQN={DATA_PREPROCESSING_RAW_SOURCE_FQP}\",  \\\n",
    "        f\"--sparkBigQueryScratchBucketUri={DATA_PREPROCESSING_SCRATCH_BUCKET}\",  \\\n",
    "        f\"--enableDataframeDisplay={True}\"]\n",
    "\n",
    "DATA_PROCESSING_BQ_SINK = f\"{PROJECT_ID}.customer_churn_ds.customer_churn_training_data\"\n",
    "DATA_PROCESSING_BQ_SINK_URI = f\"bq://{DATA_PROCESSING_BQ_SINK}\"\n",
    "\n",
    "print('DATA_PREPROCESSING_BATCH_PREFIX =',DATA_PREPROCESSING_BATCH_PREFIX)\n",
    "print('DATA_PREPROCESSING_BATCH_INSTANCE_ID =',DATA_PREPROCESSING_BATCH_INSTANCE_ID)\n",
    "print('DATA_PREPROCESSING_MAIN_PY_SCRIPT =',DATA_PREPROCESSING_MAIN_PY_SCRIPT)\n",
    "print('DATA_PREPROCESSING_RAW_SOURCE_FQP =',DATA_PREPROCESSING_RAW_SOURCE_FQP)\n",
    "print('DATA_PREPROCESSING_SCRATCH_BUCKET =',DATA_PREPROCESSING_SCRATCH_BUCKET)\n",
    "print('DATA_PREPROCESSING_ARGS =',DATA_PREPROCESSING_ARGS)\n",
    "print('DATA_PROCESSING_BQ_SINK =',DATA_PROCESSING_BQ_SINK)\n",
    "print('DATA_PROCESSING_BQ_SINK_URI =',DATA_PROCESSING_BQ_SINK_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca656c-5ae8-45ab-95a3-873fede76c01",
   "metadata": {},
   "source": [
    "#### e. Dataset registration specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50eae873-c8e8-4f0b-9bac-e83c58f64ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANAGED_DATASET_NM = f\"Customer_Churn_Model_Training_Base-{UNIQUE_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d69e4b-d088-4293-a88e-5b4d943615c8",
   "metadata": {},
   "source": [
    "#### f. Model specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfd7e0e-3b57-4c4d-a148-4357bf816b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_TRAINING_BATCH_PREFIX = customer-churn-model-training\n",
      "MODEL_TRAINING_BATCH_INSTANCE_ID = customer-churn-model-training-1544\n",
      "MODEL_TRAINING_MAIN_PY_SCRIPT = gs://s8s_code_bucket-974925525028/pyspark/model_training.py\n",
      "MODEL_TRAINING_RAW_SOURCE_FQP = s8s-spark-ml-mlops.customer_churn_ds.customer_churn_training_data\n",
      "MODEL_TRAINING_SCRATCH_BUCKET = s8s-spark-bucket-974925525028/customer-churn-model-training\n",
      "MODEL_TEST_RESULTS_TABLE_FQN = s8s-spark-ml-mlops.customer_churn_ds.customer_churn_test_predictions\n",
      "MODEL_BUCKET_URI = gs://s8s_model_bucket-974925525028/customer-churn-model-training\n",
      "MODEL_METRICS_TABLE_FQN = s8s-spark-ml-mlops.customer_churn_ds.customer_churn_model_metrics\n",
      "MODEL_FEATURE_IMP_TABLE_FQN = s8s-spark-ml-mlops.customer_churn_ds.customer_churn_model_feature_importance\n",
      "MODEL_TRAINING_ARGS = ['--appName=customer-churn-model-training', '--projectID=s8s-spark-ml-mlops', '--bigQuerySourceTableFQN=s8s-spark-ml-mlops.customer_churn_ds.customer_churn_training_data', '--bigQueryModelTestResultsTableFQN=s8s-spark-ml-mlops.customer_churn_ds.customer_churn_test_predictions', '--sparkBigQueryScratchBucketUri=s8s-spark-bucket-974925525028/customer-churn-model-training', '--sparkMlModelBucketUri=gs://s8s_model_bucket-974925525028/customer-churn-model-training', '--bigQueryModelMetricsTableFQN=s8s-spark-ml-mlops.customer_churn_ds.customer_churn_model_metrics', '--bigQueryFeatureImportanceTableFQN=s8s-spark-ml-mlops.customer_churn_ds.customer_churn_model_feature_importance', '--enableDataframeDisplay=True']\n"
     ]
    }
   ],
   "source": [
    "MODEL_TRAINING_BATCH_PREFIX = \"customer-churn-model-training\"\n",
    "MODEL_TRAINING_BATCH_INSTANCE_ID = f\"{MODEL_TRAINING_BATCH_PREFIX}-{UNIQUE_ID}\"\n",
    "MODEL_TRAINING_MAIN_PY_SCRIPT = f\"{PY_SCRIPTS_FQP}/model_training.py\"\n",
    "MODEL_TRAINING_RAW_SOURCE_FQP = f\"{DATA_PROCESSING_BQ_SINK}\"\n",
    "MODEL_TRAINING_SCRATCH_BUCKET = f\"{SCRATCH_BUCKET}/{MODEL_TRAINING_BATCH_PREFIX}\"\n",
    "MODEL_TEST_RESULTS_TABLE_FQN = f\"{PROJECT_ID}.customer_churn_ds.customer_churn_test_predictions\"\n",
    "MODEL_BUCKET_URI = f\"{MODEL_BUCKET}/{MODEL_TRAINING_BATCH_PREFIX}\"\n",
    "MODEL_METRICS_TABLE_FQN = f\"{PROJECT_ID}.customer_churn_ds.customer_churn_model_metrics\"\n",
    "MODEL_FEATURE_IMP_TABLE_FQN = f\"{PROJECT_ID}.customer_churn_ds.customer_churn_model_feature_importance\"\n",
    "MODEL_TRAINING_ARGS = [f\"--appName={MODEL_TRAINING_BATCH_PREFIX}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--bigQuerySourceTableFQN={MODEL_TRAINING_RAW_SOURCE_FQP}\",  \\\n",
    "        f\"--bigQueryModelTestResultsTableFQN={MODEL_TEST_RESULTS_TABLE_FQN}\",  \\\n",
    "        f\"--sparkBigQueryScratchBucketUri={MODEL_TRAINING_SCRATCH_BUCKET}\",  \\\n",
    "        f\"--sparkMlModelBucketUri={MODEL_BUCKET_URI}\",  \\\n",
    "        f\"--bigQueryModelMetricsTableFQN={MODEL_METRICS_TABLE_FQN}\", \\\n",
    "        f\"--bigQueryFeatureImportanceTableFQN={MODEL_FEATURE_IMP_TABLE_FQN}\", \\\n",
    "        f\"--enableDataframeDisplay={True}\"]\n",
    "\n",
    "print('MODEL_TRAINING_BATCH_PREFIX =',MODEL_TRAINING_BATCH_PREFIX)\n",
    "print('MODEL_TRAINING_BATCH_INSTANCE_ID =',MODEL_TRAINING_BATCH_INSTANCE_ID)\n",
    "print('MODEL_TRAINING_MAIN_PY_SCRIPT =',MODEL_TRAINING_MAIN_PY_SCRIPT)\n",
    "print('MODEL_TRAINING_RAW_SOURCE_FQP =',MODEL_TRAINING_RAW_SOURCE_FQP)\n",
    "print('MODEL_TRAINING_SCRATCH_BUCKET =',MODEL_TRAINING_SCRATCH_BUCKET)\n",
    "print('MODEL_TEST_RESULTS_TABLE_FQN =',MODEL_TEST_RESULTS_TABLE_FQN)\n",
    "print('MODEL_BUCKET_URI =',MODEL_BUCKET_URI)\n",
    "print('MODEL_METRICS_TABLE_FQN =',MODEL_METRICS_TABLE_FQN)\n",
    "print('MODEL_FEATURE_IMP_TABLE_FQN =',MODEL_FEATURE_IMP_TABLE_FQN)\n",
    "print('MODEL_TRAINING_ARGS =',MODEL_TRAINING_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e5090-1f28-4022-b3b1-82099710238b",
   "metadata": {},
   "source": [
    "### 2. Initialize Vertex AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c54e20-c08a-40cf-8716-09de594df623",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=SCRATCH_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3c111-17dc-4248-9df8-7c65f73c696c",
   "metadata": {},
   "source": [
    "### 3. Define Vertex AI Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dfc311b-7347-4871-9f16-9b18d4e911e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_utils_py_fqn = ['gs://s8s_code_bucket-974925525028/pyspark/common_utils.py']\n",
      "deps_bucket_fqn  = gs://s8s_code_bucket-974925525028/pyspark\n",
      "project_id  = s8s-spark-ml-mlops\n",
      "location = us-central1\n",
      "subnetwork_uri = projects/s8s-spark-ml-mlops/regions/us-central1/subnetworks/spark-snet\n",
      "spark_phs_nm = projects/s8s-spark-ml-mlops/regions/us-central1/clusters/s8s-sphs-974925525028\n",
      "container_image = gcr.io/s8s-spark-ml-mlops/dataproc_serverless_custom_runtime:1.0.2\n",
      "service_account = s8s-lab-sa@s8s-spark-ml-mlops.iam.gserviceaccount.com\n",
      "data_preprocessing_batch_id = customer-churn-data-preprocessing-1544\n",
      "data_preprocessing_main_py_fqn = gs://s8s_code_bucket-974925525028/pyspark/data_preprocessing.py\n",
      "data_preprocessing_args = ['--appName=customer-churn-data-preprocessing', '--projectID=s8s-spark-ml-mlops', '--rawDatasetBucketFQN=gs://s8s_data_bucket-974925525028/customer_churn_train_data.csv', '--sparkBigQueryScratchBucketUri=s8s-spark-bucket-974925525028/customer-churn-data-preprocessing', '--enableDataframeDisplay=True']\n"
     ]
    }
   ],
   "source": [
    "print('common_utils_py_fqn =', PYSPARK_COMMON_UTILS_SCRIPT_FQP)\n",
    "print('deps_bucket_fqn  =', PY_SCRIPTS_FQP)\n",
    "print('project_id  =', PROJECT_ID)\n",
    "print('location =', LOCATION)\n",
    "print('subnetwork_uri =', SUBNET_RESOURCE_URI)\n",
    "print('spark_phs_nm =', PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI)\n",
    "print('container_image =', DOCKER_IMAGE_FQN)\n",
    "print('service_account =', UMSA_FQN)\n",
    "\n",
    "print('data_preprocessing_batch_id =', DATA_PREPROCESSING_BATCH_INSTANCE_ID)\n",
    "print('data_preprocessing_main_py_fqn =', DATA_PREPROCESSING_MAIN_PY_SCRIPT)\n",
    "print('data_preprocessing_args =', DATA_PREPROCESSING_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346cdd5b-53a4-4760-b4f7-e595f7c20d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NM, \n",
    "    description=\"A SparkMLlib MLOps Vertex pipeline\")\n",
    "def fn_SparkMlopsPipeline(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    location: str = LOCATION,\n",
    "    service_account: str = UMSA_FQN,\n",
    "    subnetwork_uri: str = SUBNET_RESOURCE_URI,\n",
    "    spark_phs_nm: str = PERSISTENT_SPARK_HISTORY_SERVER_RESOURCE_URI,\n",
    "    container_image: str = DOCKER_IMAGE_FQN,\n",
    "    common_utils_py_fqn: list = PYSPARK_COMMON_UTILS_SCRIPT_FQP,\n",
    "    data_preprocessing_pyspark_batch_id: str = DATA_PREPROCESSING_BATCH_INSTANCE_ID,\n",
    "    data_preprocessing_main_py_fqn: str = DATA_PREPROCESSING_MAIN_PY_SCRIPT,\n",
    "    data_preprocessing_args: list = DATA_PREPROCESSING_ARGS,\n",
    "    managed_dataset_src_uri: str = DATA_PROCESSING_BQ_SINK_URI,\n",
    "    managed_dataset_nm: str = MANAGED_DATASET_NM,\n",
    "    model_training_pyspark_batch_id: str = MODEL_TRAINING_BATCH_PREFIX,\n",
    "    model_training_main_py_fqn: str = MODEL_TRAINING_MAIN_PY_SCRIPT,\n",
    "    model_training_args: list = MODEL_TRAINING_ARGS,\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.dataproc import \\\n",
    "        DataprocPySparkBatchOp\n",
    "\n",
    "    # Step 1. PRE-PROCESS DATA in PREP FOR MODEL TRAINING\n",
    "    # ....................................................................\n",
    "    dataPreprocessingStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = data_preprocessing_pyspark_batch_id,\n",
    "        main_python_file_uri = data_preprocessing_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = data_preprocessing_args\n",
    "    ).set_display_name(\"Pre-processing\")\n",
    "    \n",
    "    # Step 2. REGISTER PRE-PROCESSED DATA AS MANAGED DATASET\n",
    "    # ....................................................................\n",
    "    createManagedDatasetStep = vertex_ai_components.TabularDatasetCreateOp(\n",
    "        display_name= managed_dataset_nm,\n",
    "        bq_source=managed_dataset_src_uri,\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    ).after(dataPreprocessingStep).set_display_name(\"Dataset registration\")\n",
    "    \n",
    "    # Step 3. TRAIN MODEL\n",
    "    # .................................................................... \n",
    "    trainSparkMLModelStep = DataprocPySparkBatchOp(\n",
    "        project = project_id,\n",
    "        location = location,\n",
    "        container_image = container_image,\n",
    "        subnetwork_uri = subnetwork_uri,\n",
    "        spark_history_dataproc_cluster = spark_phs_nm,\n",
    "        service_account = service_account,     \n",
    "        batch_id = model_training_pyspark_batch_id,\n",
    "        main_python_file_uri = model_training_main_py_fqn,\n",
    "        python_file_uris = common_utils_py_fqn,\n",
    "        args = model_training_args\n",
    "    ).after(dataPreprocessingStep).set_display_name(\"Model training\")\n",
    "    \n",
    "    # Step 4. LOG MODEL METRICS INTO MODEL METASTORE\n",
    "    # .................................................................... \n",
    "    #TODO\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126d252-8cad-4615-bb65-1126792ef9e7",
   "metadata": {},
   "source": [
    "### 4. Compile the Vertex AI Pipeline into a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880c87e5-260b-4629-8a9c-f1d0814d825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(pipeline_func=fn_SparkMlopsPipeline, package_path=PIPELINE_PACKAGE_SRC_LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f665f0d-7a95-4dfb-b210-a959a3a3f914",
   "metadata": {},
   "source": [
    "### 5. Submit the Pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "156f8be4-5369-4078-8191-96ca42eeb4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/974925525028/locations/us-central1/pipelineJobs/pyspark-customer-churn-pipeline-20220726225150\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/974925525028/locations/us-central1/pipelineJobs/pyspark-customer-churn-pipeline-20220726225150')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pyspark-customer-churn-pipeline-20220726225150?project=974925525028\n"
     ]
    }
   ],
   "source": [
    "pipeline = vertex_ai.PipelineJob(\n",
    "    display_name=PIPELINE_NM,\n",
    "    template_path=PIPELINE_PACKAGE_SRC_LOCAL_PATH,\n",
    "    pipeline_root=PIPELINE_ROOT_GCS_URI,\n",
    "    enable_caching=False  # True\n",
    ")\n",
    "\n",
    "pipeline.submit(service_account=UMSA_FQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a29587-869d-43bd-bc14-4877a87c3cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
