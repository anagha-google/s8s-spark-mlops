{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e8aeb0e7-0c23-471d-ba1a-d3d733a118e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing\n",
    "This module performs data transformation in preparation for the customer churn model training.\n",
    "\n",
    "1. It reads raw data in CSV from GCS\n",
    "2. Performs some basic transformations and\n",
    "3. Persists to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gdpic-srvls-session-a4f7392b-91c6-43f2-a8de-7666310d00a8-m.us-central1-b.c.s8s-spark-ml-mlops.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://gdpic-srvls-session-a4f7392b-91c6-43f2-a8de-7666310d00a8-m:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe7b80ef040>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8023dc7c-ec1c-41a7-a049-c8e2a44a5beb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a. Arguments\n",
    "pipelineID = \"20220813\"\n",
    "projectNbr = \"974925525028\"\n",
    "projectID = \"s8s-spark-ml-mlops\"\n",
    "displayPrintStatements = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b. Variables \n",
    "bqDatasetNm = f\"{projectID}.customer_churn_ds\"\n",
    "appBaseName = \"customer-churn-model\"\n",
    "appNameSuffix = \"preprocessing\"\n",
    "appName = f\"{appBaseName}-{appNameSuffix}\"\n",
    "scratchBucketUri = f\"s8s-spark-bucket-{projectNbr}/{appBaseName}/pipelineId-{pipelineID}/{appNameSuffix}\"\n",
    "sourceBucketUri = f\"gs://s8s_data_bucket-{projectNbr}/customer_churn_train_data.csv\"\n",
    "bigQueryTargetTableFQN = f\"{bqDatasetNm}.training_data\"\n",
    "pipelineExecutionDt = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing for the *Customer Churn* experiment\n",
      ".....................................................\n",
      "The datetime now is - 20220802165809\n",
      " \n",
      "INPUT PARAMETERS-\n",
      "....pipelineID=20220813\n",
      "....projectID=s8s-spark-ml-mlops\n",
      "....projectNbr=974925525028\n",
      "....displayPrintStatements=True\n",
      " \n",
      "EXPECTED SETUP-\n",
      "....BQ Dataset=s8s-spark-ml-mlops.customer_churn_ds\n",
      "....Source Data=gs://s8s_data_bucket-974925525028/customer_churn_train_data.csv\n",
      "....Scratch Bucket for BQ connector=gs://s8s-spark-bucket-974925525028\n",
      "OUTPUT-\n",
      "....BigQuery Table=s8s-spark-ml-mlops.customer_churn_ds.training_data\n",
      "....Sample query-\n",
      "....SELECT * FROM s8s-spark-ml-mlops.customer_churn_ds.training_data WHERE pipeline_id='20220813' LIMIT 10\n"
     ]
    }
   ],
   "source": [
    "# 1c. Display input and output\n",
    "if displayPrintStatements:\n",
    "    print(\"Starting preprocessing for the *Customer Churn* experiment\")\n",
    "    print(\".....................................................\")\n",
    "    print(f\"The datetime now is - {pipelineExecutionDt}\")\n",
    "    print(\" \")\n",
    "    print(\"INPUT PARAMETERS-\")\n",
    "    print(f\"....pipelineID={pipelineID}\")\n",
    "    print(f\"....projectID={projectID}\")\n",
    "    print(f\"....projectNbr={projectNbr}\")\n",
    "    print(f\"....displayPrintStatements={displayPrintStatements}\")\n",
    "    print(\" \")\n",
    "    print(\"EXPECTED SETUP-\")  \n",
    "    print(f\"....BQ Dataset={bqDatasetNm}\")\n",
    "    print(f\"....Source Data={sourceBucketUri}\")\n",
    "    print(f\"....Scratch Bucket for BQ connector=gs://s8s-spark-bucket-{projectNbr}\") \n",
    "    print(\"OUTPUT-\")\n",
    "    print(f\"....BigQuery Table={bigQueryTargetTableFQN}\")\n",
    "    print(f\"....Sample query-\")\n",
    "    print(f\"....SELECT * FROM {bigQueryTargetTableFQN} WHERE pipeline_id='{pipelineID}' LIMIT 10\" )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Initializing spark & spark configs\n"
     ]
    }
   ],
   "source": [
    "# 2. Spark Session creation\n",
    "print('....Initializing spark & spark configs')\n",
    "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "\n",
    "# Spark configuration setting for writes to BigQuery\n",
    "spark.conf.set(\"parentProject\", projectID)\n",
    "spark.conf.set(\"temporaryGcsBucket\", scratchBucketUri)\n",
    "\n",
    "# Add Python modules\n",
    "sc.addPyFile(f\"gs://s8s_code_bucket-{projectNbr}/pyspark/common_utils.py\")\n",
    "import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Read source data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 3. Read raw data in GCS into a Spark Dataframe\n",
    "print('....Read source data')\n",
    "rawChurnDF = spark.read.options(inferSchema = True, header= True).csv(sourceBucketUri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|   PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|    Mailed check|         56.95|      1889.5|   No|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. View the data\n",
    "if displayPrintStatements:\n",
    "    print(rawChurnDF.count())\n",
    "    rawChurnDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "|summary|customerID|gender|     SeniorCitizen|Partner|Dependents|            tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|    MonthlyCharges|      TotalCharges|Churn|\n",
      "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "|  count|      7043|  7043|              7043|   7043|      7043|              7043|        7043|         7043|           7043|          7043|        7043|            7043|       7043|       7043|           7043|          7043|            7043|                7043|              7043|              7043| 7043|\n",
      "|   mean|      null|  null|0.1621468124378816|   null|      null| 32.37114865824223|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null| 64.76169246059922|2283.3004408418697| null|\n",
      "| stddev|      null|  null|0.3686116056100135|   null|      null|24.559481023094442|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null|30.090047097678482| 2266.771361883145| null|\n",
      "|    min|0002-ORFBO|Female|                 0|     No|        No|                 0|          No|           No|            DSL|            No|          No|              No|         No|         No|             No|Month-to-month|              No|Bank transfer (au...|             18.25|                  |   No|\n",
      "|    max|9995-HOTOH|  Male|                 1|    Yes|       Yes|                72|         Yes|          Yes|             No|           Yes|         Yes|             Yes|        Yes|        Yes|            Yes|      Two year|             Yes|        Mailed check|            118.75|             999.9|  Yes|\n",
      "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Profile the data\n",
    "if displayPrintStatements:\n",
    "    rawChurnDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Exploratory Data Analysis\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      11|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Check for spaces, nulls in monthly & total charges\n",
    "print('....Exploratory Data Analysis')\n",
    "if displayPrintStatements:\n",
    "    rawChurnDF.createOrReplaceTempView(\"base_customer_churn\")\n",
    "    spark.sql(\"select count(*) from base_customer_churn where MonthlyCharges is null or MonthlyCharges=' '\").show(5)\n",
    "    spark.sql(\"select count(*) from base_customer_churn where TotalCharges is null or TotalCharges=' '\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Replace space, nulls with None\n",
      "2022-08-02 16:58:34,550 - common_utils.py - INFO - ....Inside common_utils.fnReplaceSpaceWithNone\n",
      "7043\n"
     ]
    }
   ],
   "source": [
    "# 7. Replace spaces, space with null values in the TotalCharges and MonthlyCharges columns\n",
    "print('....Replace space, nulls with None')\n",
    "spaceReplacedDF = common_utils.fnReplaceSpaceWithNone(rawChurnDF)\n",
    "if displayPrintStatements:\n",
    "    print(spaceReplacedDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Replace non-numeric values in numeric columns with null\n",
      "2022-08-02 16:58:35,089 - common_utils.py - INFO - ....Inside common_utils.fnReplaceNotANumberWithNone\n",
      "7043\n"
     ]
    }
   ],
   "source": [
    "# 8. Replace non-numeric values values in the TotalCharges and MonthlyCharges columns\n",
    "print('....Replace non-numeric values in numeric columns with null')\n",
    "nanReplacedDF = common_utils.fnReplaceNotANumberWithNone(spaceReplacedDF)\n",
    "if displayPrintStatements:\n",
    "    print(nanReplacedDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Drop nulls\n",
      "7032\n"
     ]
    }
   ],
   "source": [
    "# 9. Drop rows with null in columns\n",
    "print('....Drop nulls')\n",
    "nullDroppedDF = nanReplacedDF.na.drop()\n",
    "if displayPrintStatements:\n",
    "    print(nullDroppedDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Replace -No internet service across columns- to -No-\n",
      "2022-08-02 16:58:36,237 - common_utils.py - INFO - ....Inside common_utils.fnReplaceWithNoForInternetService\n",
      "7032\n"
     ]
    }
   ],
   "source": [
    "# 10. Replace 'No internet service' across columns to 'No'\n",
    "print('....Replace -No internet service across columns- to -No-')\n",
    "partiallyProcessedDF = common_utils.fnReplaceWithNoForInternetService(nullDroppedDF)\n",
    "if displayPrintStatements:\n",
    "    print(partiallyProcessedDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Add a bin for tenure\n",
      "2022-08-02 16:58:37,006 - common_utils.py - INFO - ....Inside common_utils.fnAddBinForTenure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 11. Add a bin/bucket category for tenure range using Spark SQL and write transformed to dataframe\n",
    "print('....Add a bin for tenure')\n",
    "modelTrainingReadyDF = common_utils.fnAddBinForTenure(partiallyProcessedDF, False, spark)\n",
    "if displayPrintStatements:\n",
    "    print(modelTrainingReadyDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------------------+-------+----------+------------------+------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "|summary|CustomerID|Gender|      SeniorCitizen|Partner|Dependents|            Tenure|Tenure_Group|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|    MonthlyCharges|      TotalCharges|Churn|\n",
      "+-------+----------+------+-------------------+-------+----------+------------------+------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "|  count|      7032|  7032|               7032|   7032|      7032|              7032|        7032|        7032|         7032|           7032|          7032|        7032|            7032|       7032|       7032|           7032|          7032|            7032|                7032|              7032|              7032| 7032|\n",
      "|   mean|      null|  null|0.16240045506257111|   null|      null|32.421786120591584|        null|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null| 64.79820821201164| 2283.300441385536| null|\n",
      "| stddev|      null|  null|0.36884399675710566|   null|      null|24.545259709263245|        null|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null|30.085973913104063|2266.7713631076326| null|\n",
      "|    min|0002-ORFBO|Female|                  0|     No|        No|                 1| Tenure_0-12|          No|           No|            DSL|            No|          No|              No|         No|         No|             No|Month-to-month|              No|Bank transfer (au...|             18.25|              18.8|   no|\n",
      "|    max|9995-HOTOH|  Male|                  1|    Yes|       Yes|                72|Tenure_gt_60|         Yes|          Yes|             No|           Yes|         Yes|             Yes|        Yes|        Yes|            Yes|      Two year|             Yes|        Mailed check|            118.75|            8684.8|  yes|\n",
      "+-------+----------+------+-------------------+-------+----------+------------------+------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 12. Run summary statistics\n",
    "if displayPrintStatements:\n",
    "    modelTrainingReadyDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- SeniorCitizen: integer (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Tenure: integer (nullable = true)\n",
      " |-- Tenure_Group: string (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: float (nullable = true)\n",
      " |-- TotalCharges: float (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 13. Print schema\n",
    "modelTrainingReadyDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Format column names for consistency\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- senior_citizen: integer (nullable = true)\n",
      " |-- partner: string (nullable = true)\n",
      " |-- dependents: string (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- tenure_group: string (nullable = true)\n",
      " |-- phone_service: string (nullable = true)\n",
      " |-- multiple_lines: string (nullable = true)\n",
      " |-- internet_service: string (nullable = true)\n",
      " |-- online_security: string (nullable = true)\n",
      " |-- online_backup: string (nullable = true)\n",
      " |-- device_protection: string (nullable = true)\n",
      " |-- tech_support: string (nullable = true)\n",
      " |-- streaming_tv: string (nullable = true)\n",
      " |-- streaming_movies: string (nullable = true)\n",
      " |-- contract: string (nullable = true)\n",
      " |-- paperless_billing: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- monthly_charges: float (nullable = true)\n",
      " |-- total_charges: float (nullable = true)\n",
      " |-- churn: string (nullable = true)\n",
      " |-- pipeline_id: string (nullable = false)\n",
      " |-- pipeline_execution_dt: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 14. Format column names for consistency (title case to DB style & lowercase)\n",
    "print('....Format column names for consistency')\n",
    "persistDF = modelTrainingReadyDF.select(\"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\", \"tenure\", \"Tenure_Group\", \"PhoneService\", \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\",\"Churn\") \\\n",
    "                                .toDF(\"customer_id\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\", \"tenure\", \"tenure_group\", \"phone_service\", \"multiple_lines\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\", \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"contract\", \"paperless_billing\", \"payment_method\", \"monthly_charges\", \"total_charges\",\"churn\") \\\n",
    "                                .withColumn(\"pipeline_id\", lit(pipelineID)) \\\n",
    "                                .withColumn(\"pipeline_execution_dt\", lit(pipelineExecutionDt)) \n",
    "\n",
    "persistDF.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Persist to BQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.                                     \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "/usr/lib/spark/python/pyspark/context.py:468: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 15. Persist training dataset to a table in BQ with the pipeline ID and execution date for traceability\n",
    "print('....Persist to BQ')  \n",
    "persistDF.write.format('bigquery') \\\n",
    ".mode(\"overwrite\")\\\n",
    ".option('table', bigQueryTargetTableFQN) \\\n",
    ".save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-data-engineering",
   "notebookOrigID": 1914343434663113,
   "widgets": {}
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "serverless_spark": "{\"name\":\"projects/s8s-spark-ml-mlops/locations/us-central1/sessions/gaia-2\",\"uuid\":\"a4f7392b-91c6-43f2-a8de-7666310d00a8\",\"createTime\":\"2022-08-02T16:50:41.238350Z\",\"jupyterSession\":{},\"spark\":{},\"runtimeInfo\":{},\"state\":\"ACTIVE\",\"stateTime\":\"2022-08-02T16:51:31.808543Z\",\"creator\":\"s8s-lab-sa@s8s-spark-ml-mlops.iam.gserviceaccount.com\",\"runtimeConfig\":{\"containerImage\":\"gcr.io/s8s-spark-ml-mlops/dataproc_serverless_custom_runtime:1.0.3\",\"properties\":{\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.eventLog.dir\":\"gs://s8s-sphs-974925525028/a4f7392b-91c6-43f2-a8de-7666310d00a8/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"serviceAccount\":\"s8s-lab-sa@s8s-spark-ml-mlops.iam.gserviceaccount.com\",\"subnetworkUri\":\"https://www.googleapis.com/compute/v1/projects/s8s-spark-ml-mlops/regions/us-central1/subnetworks/spark-snet\"},\"peripheralsConfig\":{\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/s8s-spark-ml-mlops/regions/us-central1/clusters/s8s-sphs-974925525028\"}}},\"stateHistory\":[{\"state\":\"CREATING\",\"stateStartTime\":\"2022-08-02T16:50:41.238350Z\"}]}",
  "serverless_spark_kernel_name": "remote-b2e9671c5b3517283d5063a6-pyspark"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
